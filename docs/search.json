[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sneak Peak",
    "section": "",
    "text": "1 RS Learning Diary\nThis is a Quarto book to document my learning journey in Remote Sensing Cities and Environments course during my time at CASA UCL 24/25, offering insights learned, its applications, and my own reflections. The module is based on Dr Andrew Maclachlan github page [here].\n*For those of you who also want to learn Geographic Information Science beyond ‚Äòtypical GIS‚Äô Software, as in use R-Studio, you could also visit his other github page [here]."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Sneak Peak",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nHi, I‚Äôm Nooriza, a student currently pursuing a Master‚Äôs degree in Urban Spatial Science at UCL. I graduated with a degree in Geography, specializing in Regional Development Studies. Over the past five years, I have worked as a technical consultant for various governments in Indonesia, ensuring that their decision-making is data-driven. Although the results often need to pass through political and budgeting reviews, that‚Äôs essentially what I do.\nHonestly, I don‚Äôt have a specific topic of interest to add here because I have many! That‚Äôs why I chose an interdisciplinary course at CASA. One thing for sure is that I love doing analytics for social good. In the end, all the sophisticated methodologies and cutting-edge technical tools are meaningful when we use them to address challenges and solve problems, right?"
  },
  {
    "objectID": "index.html#why-do-i-choose-this-module",
    "href": "index.html#why-do-i-choose-this-module",
    "title": "Sneak Peak",
    "section": "1.2 Why do I choose this module?",
    "text": "1.2 Why do I choose this module?\nThe reason I choose remote sensing is because I want to use its vast open resources to analysis various topics. I had learned the foundations during my undergraduate degree but I haven‚Äôt delved further into it and haven‚Äôt got any experience to use GEE yet. Thus, I hope at the end of this class, I will get knowledge on to get alternative of spatial data using remote sensing plus analyse various topic across different scale using GEE.\nRemote sensing is also an interesting field as it could produce wealth of information without direct contact. Don‚Äôt you think learning remote sensing makes us have the eye of the bird even beyond? I mean we agree that remote sensing offers perspectives far beyond what our human eyes can naturally perceive : allowing to see things from above and to see the unseen of the naked eye.\n\nFor example, see the ASTER images of San Fransisco Bay below it highlights different object such as vegetation (upper left); soil & rocks in mountainous area (upper right); urban materials (lower left) ; and water temperature (lower right). It‚Äôs cool !\n\n\n\n\n\nFigure 1 : ASTER images of San Fransisco. source : NASA/JPL\nPractically, learning this course will, hopefully, help me address the challenges I faced during my previous work in Indonesia. For example, while working on a project focused on healthcare accessibility across hundreds of small islands, we struggled to obtain real-time data to identify which islands were inhabited and which were not. Additionally, we faced challenges in determining which islands had ports suitable for docking ships. I believe that applying remote sensing data is both cost- and time-efficient in helping the government maintain more precise and up-to-date data, which is particularly important in world‚Äôs largest archipelago country like Indonesia.\nFeel free to explore my site to learn more about my learning experience. Hope it helps!"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "2¬† Getting to Know Remote Sensing",
    "section": "2.1 Summary",
    "text": "2.1 Summary\nThis week, the lecture covers an introduction of remote sensing, such as its vast application, instruments, collection method, and things we have to consider when we deal with remote sensing data. I tried to make the summary using visualization below to make it easier to understand.\n\nDuring the practical, we explore several tools to deal with remote sensing data such as SNAP (Sentinel Application Platform) and R-studio to plot spectral signature. We are also introduced with 2 imagery : Sentinel-2A and Landsat-8. It is interesting how this two imagery has a global coverage and for FREE. Both of them has spectral bands that could be useful for vegetation monitoring, land cover classification, and agricultural applications. We could benefit from Sentinel-2 frequent observations to monitor rapid changes. Meanwhile, Landsat data allows us to do large areas and long-term vegetation monitoring as it has extensive historical archive and consistent global coverage. Below I discussed the application of both Landsat and Sentinel in a vegetation analysis."
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "2¬† Getting to Know Remote Sensing",
    "section": "2.2 Application",
    "text": "2.2 Application\n\nLandsat for monitoring accross vast region : Detecting of vegetation evolution across China Urban Development\n\n\nWhen I mentioned Landsat have a vast amount of historical data, @han2025 explores this historical archive of 30 years Landsat data (spanning of landsat 5 to 8) on 2.125 city to monitor the vegetation evolution, using reflective bands such as Blue, green, red, NIR and SWIR (1 and 2) and highlighting vegetation characteristics using NDVI, EVI, and OSAVI. The NDVI and RGB bands were further processed to derive texture variables, including variance, contrast, entropy, angular second moment, and correlation. These texture metrics capture spatial patterns and fine-scale structural details of urban vegetation that may not be visible through spectral bands alone. The findings will classify vegetation in urban area, whether it is decreasing or increasing over time. I genuinely believe this finding has the potential to serve as a framework for evaluating the effectiveness of the government‚Äôs long-term plan on urban greening. For instance in my country, Indonesia we have long-term regional planning that spanning for 20 years (reviewed every 5 years), the analyisis will help the policy maker to formulate more measured-target.\n\nFigure 1: A sample result shows urban vegetation degradation in Hangzhou and an increase in vegetation in Zhengzhou. source : (Han et al. 2025).\n\nHowever, Landsat is an optical imaging system that is often susceptible to cloud cover and has limitations in distinguishing different vegetation types based solely on spectral characteristics. Imagine studying a mountainous region where cloud cover is persistent‚Äîusing optical images like Landsat for vegetation monitoring and identification would be challenging.\nTo address this issue, Li et al.¬†(2023) utilized Sentinel-1, which operates with C-band Synthetic Aperture Radar (SAR), enabling vegetation mapping under all weather conditions. The SAR data from Sentinel-1, when combined with the optical imagery of Sentinel-2, allows for the production of high-resolution maps that effectively differentiate bamboo forests from other vegetation types. This integration helps overcome the limitations of optical data in vegetation monitoring, where mixed spectral characteristics often lead to uncertainty in distinguishing bamboo from other forest types."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "2¬† Getting to Know Remote Sensing",
    "section": "2.3 Reflection",
    "text": "2.3 Reflection\n\nRemote sensing provides diversity in data source, but‚Ä¶. will the implementation be easy?\n\nAfter exploring the application of the two selected satellites during practical this week, I have concluded that remote sensing data is particularly effective for analyzing large-scale and long-term variations. It can also help mitigate the high costs of manual data collection across vast regions. This insight made me reflect on a similar challenge in my country, Indonesia. We often have challenges to find dataset for spatial analysis as we rely much on vector data, if any it would be outdated. Using remote sensing data not only allows us to have more updated data but also allows us to explore various potential variables derived from satellite imagery : diversity in data sources. In my country, the Geospatial Agency has already utilized remote sensing to address time and cost constraint during data collection. It is legally published as a baseline regulation to address the conventional method for the collection and processing of geospatial data on shallow marine habitat. They use remote sensing to create a work map for on-field mapping habitat, enabling to be time and cost efficient.\nHowever I must admit despite the potential of remote sensing, its adoption in the government sector‚Äîespecially at the local level‚Äîremains limited. From my experience, this is largely due to a lack of human resources with the skills to process and analyze remote sensing data. For end users, the adoption of remote sensing is linked with the information they can bring on the table, and often might depend on the leadership, budgetary constraints, procedures and personal capacity[@nationalacademyofsciences.2003]."
  },
  {
    "objectID": "week1.html#references",
    "href": "week1.html#references",
    "title": "2¬† Getting to Know Remote Sensing",
    "section": "2.4 References",
    "text": "2.4 References\n\n\n\n\nHan, Yuan, Jianhua He, Xiaoping Du, Xiao Han, and Yaolin Liu. 2025. ‚ÄúReconstructing Urban Vegetation Evolution in China Using Multimodal Deep Learning and 30-Years Landsat Archive.‚Äù Urban Forestry & Urban Greening 103 (January): 128582. https://doi.org/10.1016/j.ufug.2024.128582."
  },
  {
    "objectID": "week2.html#summary",
    "href": "week2.html#summary",
    "title": "3¬† Xaringan and Quarto Book",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\nxaringanExtra::embed_xaringan(url = \"https://nooriza16.github.io/Xaringan/Xaringan.html\", ratio = \"16:9\")"
  },
  {
    "objectID": "week2.html#reflections",
    "href": "week2.html#reflections",
    "title": "3¬† Xaringan and Quarto Book",
    "section": "3.2 Reflections",
    "text": "3.2 Reflections\nFor someone who is not familiar with html, learning Xaringan is definitely challenging compared to powerpoint, as we just usually click tabs on power point. Honestly, I still consider power point provides more themes and more visualization effects that is easily to access compared to Xaringan. However, as I delved further I realize that using Xaringan is providing us with flexibility even such as positioned our picture. So far, I feel like Xaringan is best at incorporating snippet code on presentation or interactive features that usually too heavy to load in power point. Besides, it helps me to give a sense of what html look like."
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "4¬† Image Correction",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nHere is my note based on this week‚Äôs lecture that explores steps people usually do in image correction. Although sometimes we get a ‚Äúready-to-use data‚Äù without the need to going through all of these process, having the basic understandings of these steps would help us understand the quality our data.\n\nI also add several new terminologies, based on my own note during the lecture, related to image processing during this week‚Äôs summary\n\n\n\nReflectance and radiance\nReflectance is basically the amount of light when a surface reflect the light, while radiance is the amount of light captured by sensor after interacting with Earth‚Äôs surface\n\n\nDigital Number\nA raw value for a given pixel that represents the intensity of radiation received in a specific spectral band.\nDigital number is important because it serves as a basis for image classification, for example digital number close to 0 represents object that absorbs much incoming light (low reflectance) such as water bodies or shadows.\n\n\nDigital Object Substraction (DOS)\nDOS is an atmospheric correction method that subtracts pixel values based on the amount of difference between digital values of dark objects (usually water bodies) with their corresponding reflectance\n\n\nCollection, level, and tier\nI will use the Landsat case to explain this terminology. In Landsat the collection would be named as Collection 1 and 2, it represents the sequence of launching time and their mission : Landsat 2 is the latest. Level 1 is a scaled digital number, while level 2 is further processed data. Meanwhile, tier 1 is the highest quality data from Landsat and suitable for time series analysis.\nsource: https://www.usgs.gov/landsat-missions/landsat-collection-2-level-1-data"
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "4¬† Image Correction",
    "section": "4.2 Application",
    "text": "4.2 Application\nIn this week application, I would like to explore the application of remote sensing on my favorite topic : data unavailability. In developing countries like Indonesia, maintaining updated and comprehensive data is challenging due to time and cost constraints. A study in Pakistan also mentioned similar challenges, particularly data related to socioeconomic condition that often limited and sporadic Arshad et al. (2023). Honestly, this topic piques my interest because Bill Gates came across an article in The Washington Post and seems fascinated with the idea of using remote sensing to identify wealth, as he shared on X.\n\nFigure 1 : Tweet about satellite imagery on detecting poor region. Source : https://x.com/yohaniddawela/status/1857398431146299437\nArshad et al. (2023) addressed this issue using imagery that automatically could derive insights about poverty. They use publicly accessible high-resolution satellite imagery (Google Maps API with 16 zoom) and Landsat 7 (low resolution data). Google Maps API provides high-resolution imagery to identify man-made features like buildings and highway which are indicators of development levels meanwhile Landsat 7 is used to train Convolutional Neural Networks (a method of feature extraction from imagery in Machine Learning) in identifying nightlight bin (low to high). Areas with higher levels of economic activity and development tend to have more lights at night. This method will produce a map that indicates a poverty and development level compared to poverty line. The results are then validated using actual socioeconomic data from surveys. Below is a map where each point represents a poverty clusters (10x10 km area), comparing predicted and actual data. Green points indicate clusters above the poverty line, while red points indicates the opposite.\n\nFigure 2 : Socioeconomic conditions compared to poverty line in Pakistan. Source : (Arshad et al. 2023).\nWhen reflecting on the map above, I would prefer to visualize the classification results as polygon rather than points, as they were more intuitive. Additionally, it would be nice to map the difference across the years, Ben Abbes et al. (2024) just do this ! They use multispectral images (Landsat 5, 7,8) and Nightlight images (from Defense Meteorological Satellite Program (DMSP) and the Visible Infrared Imaging Radiometer Suite (VIIRS)) in Southeast Brazil. The classification result is represented using estimated wealth index and they could even map the socioeconomic transformation across 10 years in a single map!\n\nFigure 3 : Spatio-temporal mapping of wealth index estimations in Southeast Brazil. Source : Ben Abbes et al. (2024)."
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "4¬† Image Correction",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nI think performing Remote Sensing correction on R Studio is quite challenging, as I become more used to using ‚Äòbutton‚Äô in Remote Sensing application such as ENVI or SNAP. After this week‚Äôs lecture, I genuinely think that Remote Sensing is quite complex as it is not only an image but beyond the imagery each pixel is composed by digital number and it could be linked and better interpreted using regression too. Understanding the image classification using machine learning is also quite challenging for me, as they use new terminologies that I haven‚Äôt heard before such as convolutional neural network, epoch, and data training.\nHonestly, remote sensing combined with machine learning quite scare me off. However, I try to look beyond the methodology instead focusing on how explanatory remote sensing can be when combined with classification and prediction task, tasks machine learning good at. I think looking beyond the methodology and focusing on the exciting application has also helped me me thrive on managing challenge during this Master‚Äôs. After reading the paper, I tried to delve further into the combination of remote sensing and machine learning. If I could turn back the time, I would like to deploy this combination to make my works faster. I recalled during my works years ago, the project needed to identify thousand ports across hundred of islands in Indonesia, and we did that manually ! If I understand correctly, I could combine image classification techniques, such as convolutional neural networks, with high-resolution imagery to detect local ports used for docking ship (typically made of wood or cement) in the ocean.\n\nFigure 3 : Google Earth Imagery portraying local ports in Anambas Islands. Source : Google Earth, 2024\n\n\n\n\nArshad, Arslan, Junaid Zulfiqar, Muhammad Hassan Zaib, Ahsan Khan, and Muhammad Jahanzeb Khan. 2023. ‚ÄúMapping Socioeconomic Conditions Using Satellite Imagery: A Computer Vision Approach for Developing Countries.‚Äù Journal of Economy and Technology 1 (November): 144‚Äì63. https://doi.org/10.1016/j.ject.2023.11.001.\n\n\nBen Abbes, Ali, Jeaneth Machicao, Pedro L. P. Corr√™a, Alison Specht, Rodolphe Devillers, Jean P. Ometto, Yasuhisa Kondo, and David Mouillot. 2024. ‚ÄúDeepWealth: A Generalizable Open-Source Deep Learning Framework Using Satellite Images for Well-Being Estimation.‚Äù SoftwareX 27 (September): 101785. https://doi.org/10.1016/j.softx.2024.101785."
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "5¬† Policy",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nRecently Indonesia planned to move its capital city from Jakarta (in Java islands) into Penajam Paser Utara City (Borneo Islands), as the current capital city, Jakarta, faced an issue of sinking, land subsidence, overcrowding, low air and water quality (Bappenas 2021). The term Nusantara is used to name this new capital city, symbolizing the varied geographic settings and cultural diversities of Indonesia.\nAs for the time this published, Nusantara Development is on the phase 2 (2025-2029) that involved strengthening core area (housing, office, commercial zone). Thus, in the time being, Jakarta will still remain the capital of Indonesia until the Presidential Decree on the transfer of the capital to Nusantara is issued. The issuance of this decree will depend on the readiness of the new capital city, including the preparation of all supporting systems such as infrastructure, human resources, and governance systems.\n\nFigure 1: The Relocation Settings and Vision. source: (Capital Authority 2024)\nAs the development is still in the initial stage, the detailed planning documents haven‚Äôt been launched yet. Thus, I use available published documents regarding the detail of Nusantara‚Äôs Development which all of them are publicly available, such as Nusantara Sustainable Development Goals (SDGs) Voluntary Local Review Baseline [2024] and Nusantara Biodiversity Management Master Plan [2024]\n\nPolicy\n\nThe new capital city, Nusantara, is designed as a forest city, with 75% of its designated area being green space. This design aims to create a harmonious blend of urban development and biodiversity hotspots (Borneo Island, where Nusantara is located, is famous for its tropical rainforests). However, the design of being a forest city, its proximity to the rainforest, and its drive on landscape change would present significant challenges. One of the major concerns is the increasing likelihood of mosquito-borne diseases (such as malaria) spreading in the new capital, which are prevalent in tropical regions Surendra et al. (2024). Since malaria is both a global and local challenge, certain goals should be considered to support Nusantara‚Äôs sustainability, such as:\nA. Global Goals : Sustainable Development Goals (SDGs) 3.3 : Fight Communicable Diseases\nThe SDGs propose achievable global in combating malaria with target that in include reducing incident, mortality rates, eliminate malaria in 35 countries by 2030 and prevent resurgence of the disease in a malaria-free country. Meanwhile, Indonesia‚Äôs estimated malaria incidence per 1000 population at risk is still on range between 1-50 incidents per 1000 population in 2023. To achieve target of Global Goals, (WHO 2021) have launched global technical strategy for malaria with framework such as:\n\nFigure 2 : SDGs Goal and WHO Technical Strategy\nB.National Level : National Action Plan for Acceleration of Malaria Elimination 2020-2026\nTranslating the global goals on malaria elimination, Indonesia‚Äôs Ministry of Health (Ministry of Health and Control 2023) had proposed recommendations, including the new capital city such as:\n\nMalaria elimination policies and implementation need basic research, operational support, and efficient technology development.\nMalaria elimination policies and implementation need basic research, operational support, and efficient technology development\nPlanning and implementing malaria elimination activities are based on district endemicity stratification.\nAllocating funds from the central government to improve case finding, surveillance and vector control around Nusantara area\nC. Provincial Level : Governor Regulation 53/2023 Guidelines For Malaria Elimination Implementation Number 5 point 2\nSuppress the endemic incidents (high and medium risk)\nEliminate the number of incidents\nMaintain free malaria status (low-none risk)"
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "5¬† Policy",
    "section": "5.2 Application",
    "text": "5.2 Application\n\nRemote Sensing as Baseline for detecting malaria hotspot\n\nIn malaria elimination projects, remote sensing can serve as a crucial baseline data source for mapping malaria hotspots by integrating climatic and land-use factors. @wimberly2021 proposed a framework that leverages Earth observation products to identify mosquito habitats based on climate conditions, human activities, and specific land-use patterns.\n\nFigure 2: Framework in which Remote Sensing used in Malaria studies. source : Wimberly et al. (2021).\nTo address policy mentioned in section 2, I underlined some dataset that could be used to the analysis:\n\n\n\n\n\n\n\nData\nPurpose\n\n\n\n\n\nSentinel-2 (rainy season)\n\n\nHighlight water bodies and wetlands ‚Äì These serve as proxies for mosquito breeding sites.\nVegetation and land cover ‚Äì Provides insight into potential mosquito habitats.\nSurface temperature ‚Äì Acts as a proxy for mosquito activity.\n\n\n\n\nDigital Elevation Model (DEM) Data/Topography\n\n\nHelps to provide topografy to identify potential inundation areas, which could influence mosquito breeding patterns.\n\n\n\n\nMicrosoft Open Buildings\n\n\nUseful as a proxy for human settlements and potential exposure risk.\n\n\n\n\nRainfall Data\n\n\nThe rainfall season can be considered as a timeframe for analysis. However, if locally recorded rainfall data from the Indonesian Climatic Institution is available, it could help refine the identification of rainfall patterns, allowing for a more informed selection of the time series."
  },
  {
    "objectID": "week4.html#reflections",
    "href": "week4.html#reflections",
    "title": "5¬† Policy",
    "section": "5.3 Reflections",
    "text": "5.3 Reflections\nDuring this week, I got a lot of reflections as I finally found lecture that explicitly bridging the gap of ‚Äòacademics‚Äô to real-world policy. My reflections would be:\n\nCombining remote sensing with GIS\nSince Nusantara is still uninhabited, we could model nearby settlements to investigate the remote sensing framework. By combining the results with malaria incident data, we can validate our classification‚Äîanalyzing what percentage of high-risk areas have recorded incidents and which have not. While global and local malaria elimination frameworks mention aggregating incident data and risk levels, they do not explicitly emphasize mapping. Using maps, we can overlay malaria hotspots with incident data, land use, and socio-economic factors. As (Naserrudin, Yong, et al. 2023) notes, people are exposed to malaria due to professions that require them to venture deeper into the forest.\nRemote Sensing and GIS is good, but enriching the analysis with affected communities make it better\nBeyond remote sensing data, incorporating local knowledge can improve the analysis. Understanding how affected communities respond to malaria provides insight into the effectiveness of mitigation efforts (Naserrudin, Lin, et al. 2023). These communities have lived near rainforests for generations and are directly affected, making their experiences valuable for practical prevention strategies.\nImplementation challenges, the need for collaboration\nOne the most important key-takeaway from the lecture is that ‚Äúsome academics papers are too technical, without clearly addressed policy; some policy don‚Äôt include academic findings they could benefit for.‚Äù This condition lead to a gap between academics and urban governance. However, in my observation during my work with the government the potential cause is human resources (make the adoption of academics finding hard to implement), annual budget cycles (governments prioritize immediate results and may be reluctant to invest in the long-term experimental processes typical of academia). Bridging the gap on malaria prevention requires collaboration and commitment not only between epidemiologists, healthcare, and geospatial analysts but with the governments to ensure research translates into actionable policies."
  },
  {
    "objectID": "week4.html#references",
    "href": "week4.html#references",
    "title": "5¬† Policy",
    "section": "5.4 References",
    "text": "5.4 References\n\n\n\n\nBappenas, Kementrian PPN. 2021. ‚ÄúBuku Saku Pemindahan Ibu Kota Negara.‚Äù\n\n\nCapital Authority, Nusantara. 2024. ‚ÄúNusantara Sustainable Development GOals (SDGs) Voluntary Local Review Baseline.‚Äù\n\n\nMinistry of Health, Directorate General of Disease Prevention, and Control. 2023. ‚ÄúNational Action Plan for Acceleration of Malaria Elimination 2020-2026 (Revision).‚Äù https://malaria.kemkes.go.id/sites/default/files/2024-08/National%20Strategic%20Plan%20Revision_Malaria_29%20Mei%202023.pdf.\n\n\nNaserrudin, Nurul Athirah, Pauline Yong Pau Lin, April Monroe, Richard Culleton, Sara Elizabeth Baumann, Shigeharu Sato, Bipin Adhikari, et al. 2023. ‚ÄúExploring Barriers to and Facilitators of Malaria Prevention Practices: A Photovoice Study with Rural Communities at Risk to Plasmodium Knowlesi Malaria in Sabah, Malaysia.‚Äù BMC Public Health 23 (1): 1316. https://doi.org/10.1186/s12889-023-16173-x.\n\n\nNaserrudin, Nurul Athirah, Pauline Pau Lin Yong, April Monroe, Richard Culleton, Sara Elizabeth Baumann, Shigeharu Sato, Rozita Hod, Mohammad Saffree Jeffree, Kamruddin Ahmed, and Mohd Rohaizat Hassan. 2023. ‚ÄúSeeing Malaria Through the Eyes of Affected Communities: Using Photovoice to Document Local Knowledge on Zoonotic Malaria Causation and Prevention Practices Among Rural Communities Exposed to Plasmodium Knowlesi Malaria in Northern Borneo Island.‚Äù Malaria Journal 22 (1): 166. https://doi.org/10.1186/s12936-023-04603-5.\n\n\nSurendra, Henry, Bimandra A. Djaafara, Helen D. Prameswari, Dedy Supriyanto, Ponco Waluyo, Setyo B. Basuki, Herdiana Herdiana, et al. 2024. ‚ÄúMitigating Risks of Malaria and Other Vector-Borne Diseases in the New Capital City of Indonesia.‚Äù Nature Communications 15 (1): 10575. https://doi.org/10.1038/s41467-024-54891-x.\n\n\nWHO, World Health Organization. 2021. ‚ÄúGlobal Technical Strategy for Malaria 20162030, 2021 Update.‚Äù\n\n\nWimberly, Michael C., Kirsten M. de Beurs, Tatiana V. Loboda, and William K. Pan. 2021. ‚ÄúSatellite Observations and Malaria: New Opportunities for Research and Applications.‚Äù Trends in Parasitology 37 (6): 525‚Äì37. https://doi.org/10.1016/j.pt.2021.03.003."
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "6¬† Introduction to GEE",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nThis week‚Äôs material is all about GEE (Google Earth Engine). In a simple definition, GEE is a cloud platform that allows us to access satellite imagery for the whole world and spatial-computation on Google for free. GEE hosts massive amounts of satellite imagery and we as a user request their imagery data and analyse it on the cloud-platform without have to worry about the capability of our local machine.\nBasically, GEE has an architecture that collects user input (client side) and then process this input (server side). In GEE we could manage both raster and feature (vector) data. We input command on GEE mostly using Java Script programming language. As someone enthusiastic with GEE, the need to learn ‚Äòa new‚Äô programming language almost discourages me, as I worry that I might mix up all the programming languages I have learnt before.\nHowever, when I looked at the way GEE articulates data structures, I found it quite similar to Python, with just a few additional keywords, such as ‚Äòvar‚Äô to denote variable. Below are some basic pieces of information about the GEE language that we need to know from Andy‚Äôs lecture. Check out this introduction from Google if you‚Äôre still unconvinced [here].\n\nFigure 1 : Basic javascript in GEE. source : Andrew Maclachan Github\nWhen I was first introduced to the idea that GEE is efficient in managing raster data, I was curious about how this efficiency works. For example, if I want to use Landsat 8 (30 m resolution) to analyze the whole UK, it would require processing every 30 m pixel across the whole region, which I assumed would take longer time. However, what makes GEE faster dealing with those data actually because there is a pyramid of reduced resolution in GEE, which able to optimizes performance using lower-resolution versions of the data when full detail is not necessary and also resampling method to adapt the analysis requirement. Thus when performing analysis, GEE does not just take the original image resolution, but GEE adjusts image resolution based on our output needs. In summary, when you are zooming out and zooming in, GEE retrieves different resolution of imagery.\nAs a starter GEE interface is a bit too much, like where should I focus on because there are 3 main parts of it. Two years ago I even tried to write my first script on console panel :) because I thought it would be similar with R Studio. Come to think back on it, GEE has already put the ‚Äòsection to code‚Äô intuitively in a centre called code editor. See the picture of GEE interface below, if you are like me a starter in GEE the very first thing that anyone should notice the most is code editor : a space to write our code and for the other parts let our self become adjust to it along the time.\n\nFigure 2 : GEE Interface. source : GEE Beginer cookbook"
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "6¬† Introduction to GEE",
    "section": "6.2 Application",
    "text": "6.2 Application\n&gt;&gt; &gt;We might not be able to turn back ime, but we can look back using Landsat\nIn this section, I would like to explore the GEE strength on providing vast archive of imagery to investigate unplanned settlements during urban transformation projects. The vast historical of imagery enables researcher to look back at various critical date for development plans.@yilmaz2024 used collection of Landsat data (Landsat 5, 6,7 ) from March 1983 to February 2007. The study selected 13 urban renewal project areas in Istanbul and examined existing project data and archival satellite images. Supervised classification was performed on 10 urban renewal project areas using the GEE platform to investigate urbanization status before development plans.\nWith analysis of temporal imagery, the result show a contrasting initial condition of urban renewal‚Äôs targetted area and its projection. For instance, in Gaziosmanpasa district it is projected to be a forested area in the future, however after looking back up to one year before the approval of the development plans turns out it is highly urbanized area. The contrasting initial condition and urban renewal project in this area will present challenge to the success of the plan, as the development of greening area will fiercely compete with massively built up area.\nThis finding also underlined the issues that projected plan is not carefully consider the dominant land use of the area, which will most likely shape the future land use. As a planner, it is not easy to make sure the execution of plannings we made although we have risk mitigation in our proposed plan. However, after reading this paper I realize that we can utilize the historical archive of satellite imagery in GEE to monitor land use growth pattern before projecting its future planning target, especially to target building green space or open space among the growing built up areas.\n\nFigure 3 : Comparisan of existing land use and its projection. Source : (Yƒ±lmaz and Alkan 2024)\nThe case of comparing urban renewal project with old urban areas is interesting in urban management. However, (‚ÄúUrban Renewal Mapping: A Case Study in Beijing from 2000 to 2020,‚Äù n.d.) underlined the challenges to get enough information during the process because the lack of detection methods framework in urban renewal mapping. As we can see from the previous paper, they use random forest algorithm to identify urban and non-urban and validate using Kappa coefficients. In this paper, they propose a complete mapping framework including segmentation in detecting temporal information of urban renewal. Some key take away from their proposed framework are:\n\nData Preparation : define the urban scope and limit its boundary combined with image collections to get time series image stacks\nIdentification of old/renewed urban areas : LandTrendr fitting (algorithm to detect interannual land cover change) + segmentation of loss/grain (quantifying the dissimilarity) and random forest classification\nTemporal detection : compare extraction strategy with different loss/grain and combination of NDVI/NDBI/NDMI + validation samples\n\nOh wait.. for someone not really interested in remote sensing application in urban mapping this will be challenging, but maybe the snapshot of the result below can help you grasp the intuition of how those steps yield the result."
  },
  {
    "objectID": "week5.html#section",
    "href": "week5.html#section",
    "title": "6¬† Introduction to GEE",
    "section": "6.3 ",
    "text": "6.3 \nFigure 4 : Left : index of NDVI in time series with curve from LandTrendr ; right : urban renewal and urban old area. Source : (‚ÄúUrban Renewal Mapping: A Case Study in Beijing from 2000 to 2020,‚Äù n.d.)"
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "6¬† Introduction to GEE",
    "section": "6.4 Reflection",
    "text": "6.4 Reflection\nThe most exciting part of using Google Earth Engine (GEE) for me is the ability to share analysis results through web map applications. Clients are usually more engaged when they can interact with a visual platform that helps them understand the project better. Remote sensing analysis is often more complex than regular vector processing, so I imagine the difficulty on to deliver the results with its key preprocessing step. What makes it even harder is, we often need to switch between remote sensing desktop apps and present the results.\nBy using a web map, we make it easier for clients, even those without a technical background, to explore and understand the intuition of the analysis : what layers we have, what imagery we use, what imageries we combined. The interactive map will provide a clearer view of the project, allowing clients to see the bigger picture and stay engaged throughout the process. However, I must admit GEE is only a tool to make best use of it we need a prior fundamental concept of remote sensing, such as spectral band, enhancement, fusion, PCA, and other remote sensing pre-processing steps. Because in every script we write there should be a thinking process on why we do reduction, why we do enhancement, basically need our judgement to navigate each steps.\nI would also like to highlight the importance of domain knowledge when using the remote sensing sources, as I mentioned before GEE is just a tool the way it will yield a remarkable insight depends on the one who utilize it. For example, The Economist use satellite data to track conflict in real time. FYI, I come across this in CASA Seminar in 2023 during the time I prepared my graduate‚Äôs school application. Pediatrics could use remote sensing to understand the association of air pollution with asthma prevalence. Archaeologist can utilize remote sensing alongside other methods to understand landscape of historical sites. There are tons of use cases, right?! If you are having curious mind like me, check Dr Ollie Ballinger‚Äôs github page here to see how powerful remote sensing could be if combined with domain knowledge."
  },
  {
    "objectID": "week5.html#references",
    "href": "week5.html#references",
    "title": "6¬† Introduction to GEE",
    "section": "6.5 References",
    "text": "6.5 References\n\n\n\n\n‚ÄúUrban Renewal Mapping: A Case Study in Beijing from 2000 to 2020.‚Äù n.d. https://spj.science.org/doi/10.34133/remotesensing.0072.\n\n\nYƒ±lmaz, Okan, and Mehmet Alkan. 2024. ‚ÄúAssessing the Impact of Unplanned Settlements on Urban Renewal Projects with GEE.‚Äù Habitat International 149 (July): 103095. https://doi.org/10.1016/j.habitatint.2024.103095."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "7¬† Classification I",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nToday‚Äôs lecture is exploring remote sensing classification. Several dataset and applications mentioned are:\n\nUrban expansion/sprawl with landsat data\nSurface temperature (land and sea) with sentinel 3\nMajor air pollutants with sentinel 5\nUrban green spaces (high medium res, Lidar)\nMonitoring and illegal practices landsat data\nForest fires using landsat TM image\n\nThere are several steps to extract land cover (do classification) from earth observation data. We usually combined remote sensing with machine learning techniques that include training data, build classification model, output. Today‚Äôs class focus on classification and regression trees (CART) as a method of classification. It composes with 2 things :\na. Classification trees (yes no/ discrete values)\nIn this method, we will have predictors and target. The decision is mapped with conditions that led to yes or no decision\nb.Regression trees ( predict continuous dependant variable)\nMeanwhile, in linear regression we try to fit into the regression line, however if we have data that isn‚Äôt fitted into the data we subset this data into smaller chunks. When creating a decision tree, we would be mix all the leafes of several categories, quantified using gini impurity. And we aim to find the lowest gini impurity. We decide the breaks by creating imaginary vertical line among the data and identify the lowest sum of square residuals.\nThings to be paid attention at = OVERFITTING, dealing with this could be\na. Set the min number of pixels/ observations, Only split observations with¬†min number of 20.\nb. Pruning\nc. Removes leave, increase alfa, and find the lowest tree score. The idea is could we keep the accuracy, when we do generalizations\nd. Dividing data : training (creating trees) and testing data (applied the trees with testing data) find the lowest sum residuals.\nSee the picture :\nWe could pick some pixels as training data and validation,the machine learning will predict the value among this train and validation pixels.\nRandom forest\nAs decision tree is not good with new data, thus we could use another method is random forest. I like to use the chatgpt analogy on this:\nüí° A Decision Tree is like asking one expert for advice.\nüå≤ A Random Forest is like asking 100 experts, each with a unique take, then averaging their answers.\nApplying into imagery:\na. Supervised ( giving them a train data)\nSupport vector machine, the idea is like a logistic regression. ¬†It finds the best boundary (decision boundary) that separates different classes in the data.The benefit of this method is it allows some misclassification\nb. Unsupervised (I have train data, and I want 10 classification method) &gt; see recording (43‚Äô)\na. Usually refers to clustering/ k-means.\nb. Isodata (same with kmeans but add several inputs such as ( cluster, iterations)\nRepeat until all pixels were classified"
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "7¬† Classification I",
    "section": "7.2 Application",
    "text": "7.2 Application"
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "7¬† Classification I",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection"
  },
  {
    "objectID": "week6.html#references",
    "href": "week6.html#references",
    "title": "7¬† Classification I",
    "section": "7.4 References",
    "text": "7.4 References"
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "8¬† Classification II",
    "section": "8.1 Summary",
    "text": "8.1 Summary"
  },
  {
    "objectID": "week7.html#summary-1",
    "href": "week7.html#summary-1",
    "title": "8¬† Classification II",
    "section": "8.2 Summary",
    "text": "8.2 Summary\n1.¬†¬†¬†¬†¬† This week lecture continues last week course, about classification.\na.¬†¬†¬†¬†¬† In preprocessing data we use surface reflectance for labelling but used TOA as SR is up to 2017\nb.¬†¬†¬†¬†¬† Dynamic world what did it connect with classifications\nc.¬†¬†¬†¬†¬† Accuracy is assessed using confusion matrix\nd.¬†¬†¬†¬†¬† Issue? The large mappinf unit 50x50\ne.¬†¬†¬†¬†¬† CNN? Not giving much info about which method is good at\n2.¬†¬†¬†¬†¬† Object based image analysis\na.¬†¬†¬†¬†¬† Superpixels\nb.¬†¬†¬†¬†¬† SegOptim &gt; at the end finding the most pure end member\nIssue : only allowed to select 1 endmember for each landcover, how about mixture of landcover?\nc.¬†¬†¬†¬†¬† MESMA\nMany endmember for many landcover class\n3.¬†¬†¬†¬†¬† Confusion matrix\n-¬†¬†¬†¬†¬†¬†¬†¬†¬† The confusion matrix consists of predictive accuracy and user accuracy and its overall accuracy. This is one of accuracy assessment about the classification of model (the training) and the validated pixels\n-¬†¬†¬†¬†¬†¬†¬†¬†¬† 100-pa emission\n-¬†¬†¬†¬†¬†¬†¬†¬†¬† 100-ua omission\n-¬†¬†¬†¬†¬†¬†¬†¬†¬† Kappa coefficient &gt; same images different kappas value, no agreement on how much good kappa value"
  },
  {
    "objectID": "week7.html#application",
    "href": "week7.html#application",
    "title": "8¬† Classification II",
    "section": "8.3 Application",
    "text": "8.3 Application"
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "8¬† Classification II",
    "section": "8.4 Reflection",
    "text": "8.4 Reflection"
  },
  {
    "objectID": "week7.html#references",
    "href": "week7.html#references",
    "title": "8¬† Classification II",
    "section": "8.5 References",
    "text": "8.5 References"
  },
  {
    "objectID": "week8.html#todays-lecture-is-exploring-the-sensor-imagery-called-synthetic-aperture-radar.-the-way-it-functions-is-like-a-bat-where-it-emits-sound-and-then-the-sound-will-be-reflected-by-things-surrounding-the-bat.",
    "href": "week8.html#todays-lecture-is-exploring-the-sensor-imagery-called-synthetic-aperture-radar.-the-way-it-functions-is-like-a-bat-where-it-emits-sound-and-then-the-sound-will-be-reflected-by-things-surrounding-the-bat.",
    "title": "9¬† Synthetic Aperture Radar",
    "section": "9.1 Today‚Äôs lecture is exploring the sensor imagery called synthetic aperture radar. The way it functions is like a bat, where it emits sound and then the sound will be reflected by things surrounding the bat.",
    "text": "9.1 Today‚Äôs lecture is exploring the sensor imagery called synthetic aperture radar. The way it functions is like a bat, where it emits sound and then the sound will be reflected by things surrounding the bat.\nIts application:\na.¬†¬†¬†¬†¬† In for flooding\nIts black and white, because it goes from low (0 values) and high values, smaller portion of signals returning back to satellite the lower the value it is.\n√ò What does the flooded area appear dark in the previous image?\n√ò Calm water (and smooth surfaces) reflects the radar pulses away from the sensor\n√ò Rough surfaces reflect in all directions - more is sent back to the sensor\nThere are 2 scattering method:\na.¬†¬†¬† Rough scattering &gt; scattering the signals in many scattering way\nb.¬†¬†¬† Volume scattering &gt;\nc.¬†¬†¬† Double bounce scattering &gt;\nSAR Polarization\n1.¬†¬† V-v\n2.¬†¬† V-h"
  },
  {
    "objectID": "week8.html#application",
    "href": "week8.html#application",
    "title": "9¬† Synthetic Aperture Radar",
    "section": "9.2 Application",
    "text": "9.2 Application\nI would like to mention the application of optical remote sensing versus SAR Imagery in a research area that was initially unfamiliar to me but has become one of my interest in recent years. This week‚Äôs topic would be damage detection during conflict.\nDuring conflict, the need to assess building damage is crucial for humanitarian relief efforts. However, in the past the detection depended on eyewitness reports and manual detection. We know that time is precious during conflict and humanitarian aids. This calls (Mueller et al. 2021) to generate damage monitoring using Very High Resolution satellite imagery, good for its ever-higher resolution and frequency, and using machine learning techniques. The intuition behind the method is using Convolutional Neural Networks (CNNs) to learns from example of destruction (e.g rubble and bomb raters) to make predictions about other images. Then to address the challenges of limited amount of labeled data (because sometimes the destruction is sparse or only limited buildings destroyed), they use label-augmentation technique which assumed destroyed at a certain time building will remain destroyed in subsequent time. This assumption helps to create additional labels for training dataset. Voila, the result‚Ä¶.are shown below.\nThe image below shows damage before and after a significant heavy weaponry attack in a neighborhood of Aleppo, with red indicates patch that is destroyed.\n\nFig 1 : Damage destruction using optical satellite data. Source : Mueller et al. (2021)."
  },
  {
    "objectID": "week8.html#reflection",
    "href": "week8.html#reflection",
    "title": "9¬† Synthetic Aperture Radar",
    "section": "9.3 Reflection",
    "text": "9.3 Reflection"
  },
  {
    "objectID": "week8.html#references",
    "href": "week8.html#references",
    "title": "9¬† Synthetic Aperture Radar",
    "section": "9.4 References",
    "text": "9.4 References\n\n\n\n\nMueller, Hannes, Andre Groeger, Jonathan Hersh, Andrea Matranga, and Joan Serrat. 2021. ‚ÄúMonitoring War Destruction from Space Using Machine Learning.‚Äù Proceedings of the National Academy of Sciences of the United States of America 118 (23): e2025400118. https://doi.org/10.1073/pnas.2025400118."
  }
]