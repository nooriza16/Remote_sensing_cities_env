---
title: "Classification I "
format:
  html:
    toc: true    # Enable Table of Contents
    toc-depth: 2 # Show up to level 2 headings
---

## Summary

Take a deep breath okaaay? as today’s lecture is quite intense ! The lecture divide into 2 main points: **how classification is used** and **how to do the classifications**. Classification process in remote sensing often applied in several topics, such as:

| Topics                                    | Sensor                                                                                         |
|-------------------------------------------|------------------------------------------------------------------------------------------------|
| Urban expansion/sprawl                    | Landsat                                                                                        |
| Land Use Changes on driving air pollution | Sensor : Sentinel 3 Sea & Land Surface Temperature ; Sentinel-5 precursors major air pollution |
| Urban green spaces                        | *Several options such as high, medium resolution imagery ; Lidar-hyperspectral*                |
| Monitoring forest and illegal practices   | Landsat                                                                                        |
| Forest fires                              | landsat                                                                                        |

In practice, classification in remote sensing is combined remote with machine learning techniques that include training data, build classification model, output. Today’s class focus on classification and regression trees (CART) as a method of classification. As a visual learner, hope this diagram will help to understand it better.

![](images/clipboard-2998853873.png)

The challenge in using machine learning is OVERFITTING. In simple terms, overfitting happens when a model fits the training data too well but performs poorly on new data. To stop our data to be overfitting, there are ways to deal with this:

\(a\) Limit how the tree grows – Set the minimum number of samples per split (e.g., at least 20 observations per node)

\(b\) Pruning – Remove unnecessary branches after the tree is built to simplify

\(c\) Pruning with Alpha Regularization – Remove leaves, increase the pruning parameter (α) and find the lowest tree score. The goal is to keep the tree small without sacrificing performance.

\(d\) Data Splitting – Divide data into training (to build the tree) and testing (to evaluate performance) sets and find the lowest sum residuals in regression tasks

> How does it apply to imagery?

Applying into imagery:

a\. Supervised ( giving them a train data)

Support vector machine, the idea is like a logistic regression.  It finds the **best boundary (decision boundary)** that separates different classes in the data.The benefit of this method is it allows some misclassification

b\. Unsupervised (I have train data, and I want 10 classification method) \> see recording (43’)

a\. Usually refers to clustering/ k-means.

b\. Isodata (same with kmeans but add several inputs such as ( cluster, iterations)

Repeat until all pixels were classified

## Application

## Reflection

## References
