% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\KOMAoption{captions}{tableheading}
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={CASA 0023 Learning Diary},
  pdfauthor={Nooriza Maharani},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{CASA 0023 Learning Diary}
\author{Nooriza Maharani}
\date{2025-01-27}

\begin{document}
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[enhanced, sharp corners, frame hidden, borderline west={3pt}{0pt}{shadecolor}, breakable, interior hidden, boxrule=0pt]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\bookmarksetup{startatroot}

\hypertarget{sneak-peak}{%
\chapter{Sneak Peak}\label{sneak-peak}}

This is a Quarto book to document my learning journey in \textbf{Remote
Sensing Cities and Environments} course during my time at CASA UCL
24/25, offering insights learned, its applications, and my own
reflections. The module is based on Dr Andrew Maclachlan github page
{[}\href{https://andrewmaclachlan.github.io/CASA0023/.}{here}{]}. For
those of you who also want to learn Geographic Information Science
beyond `typical GIS' Software, as in use R-Studio, you could also visit
his other github page
{[}\href{https://andrewmaclachlan.github.io/CASA0005repo/index.html}{here}{]}.

The lecturers in this course are Dr.~Andrew Maclachlan---referred to
Andy in this learning diary---and Dr.~Ollie Ballinger---referred to as
Ollie.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Hi, I'm Nooriza Maharani, a student currently pursuing a Master's degree
in Urban Spatial Science at UCL. I graduated with a degree in Geography,
specializing in Regional Development Studies. Over the past five years,
I have worked as a technical consultant for various governments in
Indonesia, both local or ministry level, ensuring that their
decision-making is data-driven. Although the results often need to pass
through political and budgeting reviews, that's essentially what I do.
Over the years, I have assisted local governments in Indonesia managing
and utilizing spatial data to support various agendas, including land
management, land consolidation, disaster risk assessment, accessibility
analysis, and the development of both basic and thematic databases.

Honestly, I don't have a specific topic of interest to add here because
I have many! From health to art, from sport analytic to social analytic.
I love to connect them all with spatial. That's why I chose an
interdisciplinary course at CASA. One thing for sure is that I love
doing analytics for social good. I love to look beyond tools and
methodologies, focusing instead on the challenges we can address using
these methods. In the end, all the sophisticated methodologies and
cutting-edge technical tools are meaningful when we use them to address
challenges and solve problems, right?

\hypertarget{why-do-i-choose-this-module}{%
\section{Why do I choose this
module?}\label{why-do-i-choose-this-module}}

The reason I choose remote sensing is because I want to use its vast
open resources to analysis various topics. I had learned the foundations
during my undergraduate degree but I haven't delved further into it and
haven't got any experience to use GEE yet. Thus, I hope at the end of
this class, I will get knowledge on to get alternative of spatial data
using remote sensing plus analyse various topic across different scale
using GEE.

Remote sensing is also an interesting field as it could produce wealth
of information without direct contact. Don't you think learning remote
sensing makes us have the eye of the bird even beyond? I mean we agree
that remote sensing offers perspectives far beyond what our human eyes
can naturally perceive such as \emph{allowing} to \emph{see things from
above and to see the unseen with the naked eye.}

\includegraphics[width=3.76042in,height=\textheight]{images/clipboard-2217286199.png}

Figure 1: Seeing things from above. source :
\href{https://chirpforbirds.com/nature-advocacy/biomimicry-and-birds/}{Chirps
Nature Centre}

For example, see the ASTER images of San Fransisco Bay below it
highlights different object such as vegetation (upper left); soil \&
rocks in mountainous area (upper right); urban materials (lower left) ;
and water temperature (lower right). All from one image\ldots that's
cool !

\begin{figure}

\href{https://photojournal.jpl.nasa.gov/jpegMod/PIA02605_modest.jpg}{\includegraphics[width=3.78125in,height=\textheight]{images/PIA02605_modest.jpg}}

\end{figure}

Figure 1 : ASTER images of San Fransisco. source :
\href{https://photojournal.jpl.nasa.gov/catalog/PIA02605}{NASA/JPL}

Practically, learning this course will, hopefully, help me address the
challenges I faced during my previous work in Indonesia. For example,
while working on a project focused on healthcare accessibility across
hundreds of small islands, we struggled to obtain latest data to
identify which islands were inhabited and which were not. Additionally,
we faced challenges in determining which islands had ports suitable for
docking ships. I believe that applying remote sensing data is both cost-
and time-efficient in helping the government maintain more precise and
up-to-date data, which is particularly important in world's largest
archipelago country like Indonesia.

Feel free to explore my site to learn more about my learning experience.
Hope it helps!

\bookmarksetup{startatroot}

\hypertarget{getting-to-know-remote-sensing}{%
\chapter{Getting to Know Remote
Sensing}\label{getting-to-know-remote-sensing}}

\hypertarget{summary}{%
\section{\texorpdfstring{\textbf{Summary}}{Summary}}\label{summary}}

This week, the lecture covers an introduction of remote sensing, such as
its vast application, instruments, collection method, and things we have
to consider when we deal with remote sensing data. I tried to make the
summary using visualization below to make it easier to understand.

\includegraphics{images/clipboard-1084697230.png}

During the practical, we explore several tools to deal with remote
sensing data such as SNAP (Sentinel Application Platform) and R-studio
to plot spectral signature. We are also introduced with 2 imagery :
Sentinel-2A and Landsat-8. It is interesting how this two imagery has a
global coverage and for FREE. Both of them has spectral bands that could
be useful for vegetation monitoring, land cover classification, and
agricultural applications. We could benefit from Sentinel-2 frequent
observations to monitor rapid changes. Meanwhile, Landsat data allows us
to do large areas and long-term vegetation monitoring as it has
extensive historical archive and consistent global coverage. Below I
discussed the application of both Landsat and Sentinel in a vegetation
analysis.

\hypertarget{application}{%
\section{\texorpdfstring{\textbf{Application}}{Application}}\label{application}}

\begin{quote}
\textbf{Landsat for monitoring accross vast region : Detecting of
vegetation evolution across China Urban Development}
\end{quote}

\begin{itemize}
\item
  When I mentioned Landsat have a vast amount of historical data, Han et
  al. (2025) explores this historical archive of 30 years Landsat data
  (spanning of landsat 5 to 8) on 2.125 city to monitor the vegetation
  evolution, using reflective bands such as Blue, green, red, NIR and
  SWIR (1 and 2) and highlighting vegetation characteristics using NDVI,
  EVI, and OSAVI. The NDVI and RGB bands were further processed to
  derive texture variables, including variance, contrast, entropy,
  angular second moment, and correlation. These texture metrics capture
  spatial patterns and fine-scale structural details of urban vegetation
  that may not be visible through spectral bands alone. The findings
  will classify vegetation in urban area, whether it is decreasing or
  increasing over time.

  \includegraphics[width=6.96875in,height=\textheight]{images/clipboard-1072383063.png}

  Figure 1: A sample result shows urban vegetation degradation in
  Hangzhou and an increase in vegetation in Zhengzhou. source : (Han et
  al. 2025).
\end{itemize}

However, Landsat is an optical imaging system that is often
\textbf{susceptible to cloud cover} and has limitations in
distinguishing different vegetation types based solely on spectral
characteristics. Imagine studying a mountainous region where cloud cover
is persistent---using optical images like Landsat for vegetation
monitoring and identification would be challenging. To address this
issue, Li et al. (2023) utilized Sentinel-1, which operates with C-band
Synthetic Aperture Radar (SAR), enabling vegetation mapping under all
weather conditions. The SAR data from Sentinel-1, when combined with the
optical imagery of Sentinel-2, allows for the production of
high-resolution maps that effectively differentiate bamboo forests from
other vegetation types. This integration helps overcome the limitations
of optical data in vegetation monitoring, where mixed spectral
characteristics often lead to uncertainty in distinguishing bamboo from
other forest types.

During my time understanding this paper, I was thinking that Landsat's
vast amount of historical data has the potential to serve as a framework
for evaluating the effectiveness of the \textbf{government's long-term}
plan on urban greening. t must be challenging for the current government
to evaluate which planning schemes have led to present conditions
without access to extensive historical data. As a result, assessing the
effectiveness of previous plans, identifying trends, and making informed
adjustments for future development becomes difficult. For instance, in
my country, Indonesia, we have long-term regional planning spanning 20
years, with reviews every five years. However, making accurate
projections over such a long period can be challenging, even with
periodic reviews. By utilizing Earth observation and historical imagery,
we can improve our ability to project urban greenery developments and
implement more realistic and measurable strategies

\hypertarget{reflection}{%
\section{Reflection}\label{reflection}}

\emph{Remote sensing provides diversity in data source, but\ldots. will
the implementation be easy?}

After exploring the application of the two selected satellites during
practical this week, I have concluded that remote sensing data is
particularly effective for analyzing large-scale and long-term
variations. It can help to mitigate the high costs of manual data
collection across vast regions. This insight made me reflect a lot on a
similar challenge in my country. We often have challenges to find
dataset for spatial analysis as we rely much on vector data, if any it
would be outdated. Using remote sensing data not only allows us to have
more updated data but also allows us to explore various potential
variables derived from satellite imagery. However I must admit despite
the potential of remote sensing, its adoption in the government
sector---especially at the local level---remains limited. From my
experience, this is largely due to a lack of human resources with the
skills to process and analyze remote sensing data. For end users, the
adoption of remote sensing is heavily linked with the information they
can bring on the table, and often might depend on the leadership,
budgetary constraints, procedures and personal capacity (National
Academy of Sciences. 2003).

Future Applications: I want to use remote sensing to map and analyze how
river meandering evolves after the rainy season in my hometown. I have
wanted to do this mini-project for years, but since I have not yet fully
understood the methods and applications of remote sensing, I have not
been able to accomplish it. This interest stems from my childhood
observations---back then, the distance between the settlement and the
river felt quite far. However, in recent years, I have noticed that the
river has become visible from just a kilometer away from my house. In
fact, around 2022, during a particularly heavy rainy season, the
embankment collapsed, causing a house to be swept away into the river.
Honestly, that accident often haunts me when the rainy season arrives. I
just want to verify if my observations are accurate through remote
sensing analysis and understand the potential risks for future
precautions

\hypertarget{references}{%
\section{References}\label{references}}

\bookmarksetup{startatroot}

\hypertarget{xaringan-and-quarto-book}{%
\chapter{Xaringan and Quarto Book}\label{xaringan-and-quarto-book}}

Lecture this week reminded me of one of powerful figure in Uchiha Clan,
the one who can manipulate reality once he activates this-so-called
Xaringan. Well, but this Xaringan is not related to figures in Konoha's
world but related to a certain library in R Studio that enable us to
create neat HTML slides in R.

I think a presentation is basically a way to communicate insights to the
audience, and a great presentation may even ``hypnotize'' the audience.
Is that one of reasons it called Xaringan?

\hypertarget{summary-1}{%
\section{Summary}\label{summary-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xaringanExtra}\SpecialCharTok{::}\FunctionTok{embed\_xaringan}\NormalTok{(}\AttributeTok{url =} \StringTok{"https://nooriza16.github.io/Xaringan/Xaringan.html"}\NormalTok{, }\AttributeTok{ratio =} \StringTok{"16:9"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{reflections}{%
\section{Reflections}\label{reflections}}

For someone who is not familiar with html, learning Xaringan is
definitely challenging compared to powerpoint, as we just usually click
tabs on power point. Honestly, I still consider power point provides
more themes and more visualization effects that is easily to access
compared to Xaringan. However, as I delved further I realize that using
Xaringan is providing us with flexibility even such as positioned our
picture. So far, I feel like Xaringan is best at incorporating snippet
code on presentation or interactive features that usually too heavy to
load in power point. Besides, it helps me to give a sense of what html
look like.

\bookmarksetup{startatroot}

\hypertarget{image-correction}{%
\chapter{Image Correction}\label{image-correction}}

\hypertarget{summary-2}{%
\section{Summary}\label{summary-2}}

Here is my note based on this week's lecture that explores steps people
usually do in image correction. Although sometimes we get a
``ready-to-use data'' without the need to going through all of these
process, having the basic understandings of these steps would help us
understand the quality our data.

\includegraphics{images/clipboard-3039716080.png}

I also add several new terminologies, based on my own note during the
lecture, related to image processing during this week's summary

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.0935}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.9065}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Reflectance and radiance} & Reflectance is basically the amount
of light when a surface reflect the light, while radiance is the amount
of light captured by sensor after interacting with Earth's surface \\
\textbf{Digital Number} & A raw value for a given pixel that represents
the intensity of radiation received in a specific spectral band.

Digital number is important because it serves as a basis for image
classification, for example digital number close to 0 represents object
that absorbs much incoming light (low reflectance) such as water bodies
or shadows. \\
\textbf{Digital Object Substraction (DOS)} & DOS is an atmospheric
correction method that subtracts pixel values based on the amount of
difference between digital values of dark objects (usually water bodies)
with their corresponding reflectance \\
\textbf{Collection, level, and tier} & I will use the Landsat case to
explain this terminology. In Landsat the collection would be named as
Collection 1 and 2, it represents the sequence of launching time and
their mission : Landsat 2 is the latest. Level 1 is a scaled digital
number, while level 2 is further processed data. Meanwhile, tier 1 is
the highest quality data from Landsat and suitable for time series
analysis.

source:
\url{https://www.usgs.gov/landsat-missions/landsat-collection-2-level-1-data} \\
\end{longtable}

\hypertarget{application-1}{%
\section{Application}\label{application-1}}

In this week application, I would like to explore the application of
remote sensing on my favorite topic : data unavailability. In developing
countries like Indonesia, maintaining updated and comprehensive data is
challenging due to time and cost constraints. A study in Pakistan also
mentioned similar challenges, particularly data related to socioeconomic
condition that often limited and sporadic (Arshad et al. 2023).
Honestly, this topic piques my interest because Bill Gates came across
an article in The Washington Post and seems fascinated with the idea of
using remote sensing to identify poverty, as he shared on X.

\includegraphics[width=2.66667in,height=\textheight]{images/clipboard-3275173560.png}

Figure 1 : Tweet about satellite imagery on detecting poor region.
Source :
\href{https://x.com/yohaniddawela/status/1857398431146299437}{Twitter}

Arshad et al. (2023) addressed those challenges by deriving information
through satellite imagery. They use publicly accessible high-resolution
satellite imagery (Google Maps API with 16 zoom) and Landsat 7 (low
resolution data). Google Maps API provides high-resolution imagery to
identify man-made features like buildings and highway which are
indicators of development levels meanwhile Landsat 7 is used to train
Convolutional Neural Networks (a method of feature extraction from
imagery in Machine Learning) in identifying nightlight bin (low to
high). Areas with higher levels of economic activity and development
tend to have more lights at night. This method will produce a map that
indicates a poverty and development level compared to poverty line. The
results are then validated using actual socioeconomic data from surveys.
Below is a map where each point represents a poverty clusters (10x10 km
area), comparing predicted and actual data. Green points indicate
clusters above the poverty line, while red points indicates the
opposite.

\includegraphics[width=6.25in,height=\textheight]{images/clipboard-4160873008.png}

Figure 2 : Socioeconomic conditions compared to poverty line in
Pakistan. Source : (Arshad et al. 2023).

When reflecting on the map above, I would prefer to visualize the
classification results as polygon rather than points, as they were more
intuitive. Additionally, it would be nice to map the difference across
the years, Ben Abbes et al. (2024) just do this ! They use multispectral
images (Landsat 5, 7,8) and Nightlight images (from Defense
Meteorological Satellite Program (DMSP) and the Visible Infrared Imaging
Radiometer Suite (VIIRS)) in Southeast Brazil. The classification result
is represented using an estimated wealth index, and it can even map
socioeconomic transformation over 10 years in a single map! I think the
map is quite brilliant. He takes the delta between the latest and past
data and visualizes it with a gradual color scale. The stronger the hue,
the larger the margin

\includegraphics[width=6.03125in,height=\textheight]{images/clipboard-422155352.png}

Figure 3 : Spatio-temporal mapping of wealth index estimations in
Southeast Brazil. Source : Ben Abbes et al. (2024).

\hypertarget{reflection-1}{%
\section{Reflection}\label{reflection-1}}

I think performing Remote Sensing correction on R Studio is quite
challenging, as I become more used to using `button' in Remote Sensing
application such as ENVI or SNAP. After this week's lecture, I genuinely
think that Remote Sensing is quite complex as it is not only an image
but beyond the imagery each pixel is composed by digital number and it
could be linked and better interpreted using regression too.
Understanding the image classification using machine learning is also
quite challenging for me, as they use new terminologies that I haven't
heard before such as convolutional neural network, epoch, and data
training.

Honestly, remote sensing combined with machine learning quite scare me
off. However, I try to look beyond the methodology instead focusing on
how explanatory remote sensing can be when combined with classification
and prediction task, tasks machine learning good at. I think looking
beyond the methodology and focusing on the exciting application has also
helped me me thrive on managing challenge during this Master's. After
reading the paper, I tried to delve further into the combination of
remote sensing and machine learning. If I could turn back the time, I
would like to deploy this combination to make my works faster. I
recalled during my works years ago, the project needed to identify
thousand ports across hundred of islands in Indonesia, and we did that
manually ! If I understand correctly, I could combine image
classification techniques, such as convolutional neural networks, with
high-resolution imagery to detect local ports used for docking ship
(typically made of wood or cement) in the ocean.

\includegraphics{images/clipboard-2420843413.png}

Figure 3 : Google Earth Imagery portraying local ports in Anambas
Islands. Source : Google Earth, 2024

\hypertarget{references-1}{%
\section{References}\label{references-1}}

\bookmarksetup{startatroot}

\hypertarget{policy}{%
\chapter{Policy}\label{policy}}

\textbf{Project Case : A New Relocated Capital City of Indonesia ; From
Jakarta to Nusantara}

\includegraphics[width=9.82292in,height=\textheight]{images/clipboard-546673402.png}

Source :
\href{https://www.nytimes.com/interactive/2023/05/16/headway/indonesia-nusantara-jakarta.html}{www.nytimes.com}

\hypertarget{summary-3}{%
\section{Summary}\label{summary-3}}

Recently Indonesia planned to move its capital city from Jakarta (in
Java islands) into Penajam Paser Utara City (Borneo Islands), as the
current capital city, Jakarta, faced an issue of sinking, land
subsidence, overcrowding, low air and water quality (Bappenas 2021). The
term Nusantara is used to name this new capital city, symbolizing the
varied geographic settings and cultural diversities of Indonesia.

As for the time this published, Nusantara Development is on the phase 2
(2025-2029) that involved strengthening core area (housing, office,
commercial zone). Thus, in the time being, Jakarta will still remain the
capital of Indonesia until the Presidential Decree on the transfer of
the capital to Nusantara is issued. The issuance of this decree will
depend on the readiness of the new capital city, including the
preparation of all supporting systems such as infrastructure, human
resources, and governance systems.

\includegraphics[width=6.07292in,height=\textheight]{images/clipboard-3462147358.png}

Figure 1: The Relocation Settings and Vision. source: (Capital Authority
2024)

As the development is still in the initial stage, the detailed planning
documents haven't been launched yet. Thus, I use available published
documents regarding the detail of Nusantara's Development which all of
them are publicly available, such as
\href{https://www.ikn.go.id/storage/pedoman-nusantara/2/nusantara-vlr-baseline-en.pdf}{Nusantara
Sustainable Development Goals (SDGs) Voluntary Local Review Baseline
{[}2024{]}} and
\href{https://ikn.go.id/storage/pedoman-nusantara/1/nusantara-biodiversity-management-master-plan-2024.pdf}{Nusantara
Biodiversity Management Master Plan} {[}2024{]}

\begin{quote}
\textbf{Policy}
\end{quote}

The new capital city, Nusantara, is designed as a \textbf{forest city},
with 75\% of its designated area being green space. This design aims to
create a harmonious blend of urban development and biodiversity hotspots
(Borneo Island, where Nusantara is located, is famous for its tropical
rainforests). However, the design of being a forest city, its proximity
to the rainforest, and its drive on landscape change would present
significant \textbf{challenges}. One of the major concerns is the
increasing likelihood of mosquito-borne diseases (such as
\textbf{malaria}) spreading in the new capital, which are prevalent in
tropical regions Surendra et al. (2024). Since malaria is both a global
and local challenge, certain goals should be considered to support
Nusantara's sustainability, such as:

\textbf{A. Global Goals :} Sustainable Development Goals (SDGs) 3.3 :
Fight Communicable Diseases

The SDGs propose achievable global in combating malaria with target that
in include reducing incident, mortality rates, eliminate malaria in 35
countries by 2030 and prevent resurgence of the disease in a
malaria-free country. Meanwhile, Indonesia's estimated malaria incidence
per 1000 population at risk is still on range between 1-50 incidents per
1000 population in 2023. To achieve target of Global Goals, (WHO 2021)
have launched global technical strategy for malaria with framework such
as:

\includegraphics[width=7.76042in,height=\textheight]{images/clipboard-2410472720.png}

Figure 2 : SDGs Goal and WHO Technical Strategy

\textbf{B.National Level :} National Action Plan for Acceleration of
Malaria Elimination 2020-2026

Translating the global goals on malaria elimination, Indonesia's
Ministry of Health (Ministry of Health and Control 2023) had proposed
recommendations, including the new capital city such as:

\begin{itemize}
\item
  Malaria elimination policies and implementation need basic research,
  operational support, and efficient technology development.
\item
  Malaria elimination policies and implementation need basic research,
  operational support, and efficient technology development
\item
  Planning and implementing malaria elimination activities are based on
  district endemicity stratification.
\item
  Allocating funds from the central government to improve case finding,
  surveillance and vector control around Nusantara area

  \textbf{C.} \textbf{Provincial Level :} Governor Regulation 53/2023
  Guidelines For Malaria Elimination Implementation Number 5 point 2
\item
  Suppress the endemic incidents (high and medium risk)
\item
  Eliminate the number of incidents
\item
  Maintain free malaria status (low-none risk)
\end{itemize}

\hypertarget{application-2}{%
\section{Application}\label{application-2}}

\begin{quote}
Remote Sensing as Baseline for detecting malaria hotspot
\end{quote}

In malaria elimination projects, remote sensing can serve as a crucial
baseline data source for mapping malaria hotspots by integrating
climatic and land-use factors. @wimberly2021 proposed a framework that
leverages Earth observation products to identify mosquito habitats based
on climate conditions, human activities, and specific land-use patterns.

\includegraphics[width=7in,height=\textheight]{images/clipboard-687725868.png}

Figure 2: Framework in which Remote Sensing used in Malaria studies.
source : Wimberly et al. (2021).

To address policy mentioned in section 2, I underlined some dataset that
could be used to the analysis:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.1609}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.8391}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Data
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Purpose
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  \textbf{Sentinel-2 (rainy season)}
\end{itemize}
\end{minipage} & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\item
  \emph{Highlight water bodies and wetlands} -- These serve as proxies
  for mosquito breeding sites.
\item
  \emph{Vegetation and land cover} -- Provides insight into potential
  mosquito habitats.
\item
  \emph{Surface temperature} -- Acts as a proxy for mosquito activity.
\end{itemize}
\end{minipage} \\
\begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  \textbf{Digital Elevation Model (DEM) Data/Topography}
\end{itemize}
\end{minipage} & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  Helps to provide topografy to identify potential inundation areas,
  which could influence mosquito breeding patterns.
\end{itemize}
\end{minipage} \\
\begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  \textbf{Microsoft Open Buildings}
\end{itemize}
\end{minipage} & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  Useful as a proxy for human settlements and potential exposure risk.
\end{itemize}
\end{minipage} \\
\begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  \textbf{Rainfall Data}
\end{itemize}
\end{minipage} & \begin{minipage}[t]{\linewidth}\raggedright
\begin{itemize}
\tightlist
\item
  The rainfall season can be considered as a timeframe for analysis.
  However, if locally recorded rainfall data from the Indonesian
  Climatic Institution is available, it could help refine the
  identification of rainfall patterns, allowing for a more informed
  selection of the time series.
\end{itemize}
\end{minipage} \\
\end{longtable}

\hypertarget{reflections-1}{%
\section{Reflections}\label{reflections-1}}

During this week, I got a lot of reflections as I finally found lecture
that explicitly bridging the gap of `academics' to real-world policy. My
reflections would be:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Combining remote sensing with GIS

  Since Nusantara is still uninhabited, we could model nearby
  settlements to investigate the remote sensing framework. By combining
  the results with malaria incident data, we can validate our
  classification---analyzing what percentage of high-risk areas have
  recorded incidents and which have not. While global and local malaria
  elimination frameworks mention aggregating incident data and risk
  levels, they do not explicitly emphasize mapping. Using maps, we can
  overlay malaria hotspots with incident data, land use, and
  socio-economic factors. As (Naserrudin, Yong, et al. 2023) notes,
  people are exposed to malaria due to professions that require them to
  venture deeper into the forest.
\item
  Remote Sensing and GIS is good, but enriching the analysis with
  \textbf{affected communities} make it better

  Beyond remote sensing data, incorporating local knowledge can improve
  the analysis. Understanding how affected communities respond to
  malaria provides insight into the effectiveness of mitigation efforts
  (Naserrudin, Lin, et al. 2023). These communities have lived near
  rainforests for generations and are directly affected, making their
  experiences valuable for practical prevention strategies.
\item
  Implementation challenges, the need for collaboration

  One the most important key-takeaway from the lecture is that ``some
  academics papers are too technical, without clearly addressed policy;
  some policy don't include academic findings they could benefit for.''
  This condition lead to a gap between academics and urban governance.
  However, in my observation during my work with the government the
  potential cause is human resources (make the adoption of academics
  finding hard to implement), annual budget cycles (governments
  prioritize immediate results and may be reluctant to invest in the
  long-term experimental processes typical of academia). Bridging the
  gap on malaria prevention requires collaboration and commitment not
  only between epidemiologists, healthcare, and geospatial analysts but
  with the governments to ensure research translates into actionable
  policies.
\end{enumerate}

\hypertarget{references-2}{%
\section{References}\label{references-2}}

\bookmarksetup{startatroot}

\hypertarget{introduction-to-gee}{%
\chapter{Introduction to GEE}\label{introduction-to-gee}}

\hypertarget{summary-4}{%
\section{Summary}\label{summary-4}}

This week's material is all about GEE (Google Earth Engine). In a simple
definition, GEE is a cloud platform that allows us to access satellite
imagery for the whole world and spatial-computation on Google for free.
GEE hosts massive amounts of satellite imagery and we as a user request
their imagery data and analyse it on the cloud-platform without have to
worry about the capability of our local machine.

Basically, GEE has an architecture that collects user input (client
side) and then process this input (server side). In GEE we could manage
both raster and feature (vector) data. We input command on GEE mostly
using Java Script programming language. As someone enthusiastic with
GEE, the need to learn `a new' programming language almost discourages
me, as I worry that I might mix up all the programming languages I have
learnt before.

However, when I looked at the way GEE articulates data structures, I
found it quite similar to Python, with just a few additional keywords,
such as `var' to denote variable. Below are some basic pieces of
information from Andy's lecture about the GEE language that GEE starters
need to know. Check out this introduction from Google if you're still
unconvinced

\includegraphics[width=5.29167in,height=\textheight]{images/clipboard-203956171.png}

Figure 1 : Basic javascript in GEE. source :
\href{https://andrewmaclachlan.github.io/CASA0023/5_GEE_I.html}{Andrew
Maclachan Github}

When I was first introduced to the idea that GEE is efficient in
managing raster data, I was curious about how this efficiency works. For
example, if I want to use Landsat 8 (30 m resolution) to analyze the
whole UK, it would require processing every 30 m pixel across the whole
region, which I assumed would take longer time. However, what makes GEE
faster dealing with those data actually because there is a pyramid of
reduced resolution in GEE, which able to optimizes performance using
lower-resolution versions of the data when full detail is not necessary
and also resampling method to adapt the analysis requirement. Thus when
performing analysis, GEE does not just take the original image
resolution, but GEE adjusts image resolution based on our output needs.
In summary, when you are zooming out and zooming in, GEE retrieves
different resolution of imagery.

As a starter GEE interface is a bit too much, like where should I focus
on because there are 3 main parts of it. Two years ago I even tried to
write my first script on console panel :) because I thought it would be
similar with R Studio. Come to think back on it, GEE has already put the
`section to code' intuitively in a centre called code editor. See the
picture of GEE interface below, if you are like me a starter in GEE the
very first thing that anyone should notice the most is code editor : a
space to write our code and for the other parts let our self become
adjust to it along the time.

\includegraphics[width=7.17708in,height=\textheight]{images/ee-editor_1920.png}

Figure 2 : GEE Interface. source :
\href{https://developers.google.com/earth-engine/tutorials/community/beginners-cookbook}{GEE
Beginer cookbook}

\hypertarget{application-3}{%
\section{Application}\label{application-3}}

\textgreater\textgreater{} \textgreater``\emph{We might not be able to
turn back time, but well\ldots.. we sure can look back using
Landsat''}\textless\textless{}

In this section, I would like to explore the \textbf{GEE strength on
providing vast archive} of imagery to investigate unplanned settlements
during urban transformation projects. The vast historical of imagery
enables researcher to look back at various critical date for development
plans. @yilmaz2024 used collection of Landsat data (Landsat 5, 6,7 )
from March 1983 to February 2007 to compare land use before and after
urban renewal project happen. When I pondered upon this it is like
investigating planning product in a sense of is it \emph{planning to
fail or failing to plan?}

With analysis of temporal imagery, the result show a contrasting initial
condition of urban renewal's targetted area and its projection. For
instance, in Gaziosmanpasa district it is projected to be a forested
area in the future, however after looking back up to one year before the
approval of the development plans turns out it is highly urbanized area.
The contrasting initial condition and urban renewal project in this area
will present challenge to the success of the plan, as the development of
greening area will fiercely compete with massively built up area.

This finding also underlined the \emph{issues} that projected plan is
not carefully consider the dominant land use of the area, which will
most likely shape the future land use. As a planner, it is not easy to
make sure the execution of plannings we made although we have risk
mitigation in our proposed plan. However, after reading this paper I
realize that we can utilize the historical archive of satellite imagery
in GEE to monitor land use growth pattern before projecting its future
planning target, especially to target building green space or open space
among the growing built up areas.

\includegraphics[width=7.58333in,height=\textheight]{images/clipboard-3598015637.png}

Figure 3 : Comparisan of existing land use and its projection. Source :
Yılmaz and Alkan (2024){]}

The case of comparing urban renewal project with old urban areas is
interesting in urban management. However, {``Urban Renewal Mapping: A
Case Study in Beijing from 2000 to 2020''} (n.d.) underlined the
challenges to get enough information during the process because
\textbf{the lack of detection methods framework in urban renewal
mapping}. As we can see from the previous paper, they use random forest
algorithm to identify urban and non-urban and validate using Kappa
coefficients. In this paper, they propose a complete mapping framework
including segmentation in detecting temporal information of urban
renewal. Some key take away from their proposed framework are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Data Preparation : define the urban scope and limit its boundary
  combined with image collections to get time series image stacks
\item
  Identification of old/renewed urban areas : LandTrendr fitting
  (algorithm to detect inter-annual land cover change) + segmentation of
  loss/grain (quantifying the dissimilarity) and random forest
  classification
\item
  Temporal detection : compare extraction strategy with different
  loss/grain and combination of NDVI/NDBI/NDMI + validation samples
\end{enumerate}

Oh wait\ldots.for someone who is not really interested in remote
sensing's application in urban mapping this will be challenging, but
maybe the snapshot of the result below can help you grasp the intuition
of how those steps yield the result. We can see from the left picture
that we could have NDVI index graph to explain the built-up area

\includegraphics[width=7.83333in,height=\textheight]{images/clipboard-2246403998.png}

Figure 4 : Left : index of NDVI in time series with curve from
LandTrendr ; right : urban renewal and urban old area. Source :
({``Urban Renewal Mapping: A Case Study in Beijing from 2000 to 2020,''}
n.d.)

\hypertarget{reflection-2}{%
\section{Reflection}\label{reflection-2}}

The most exciting part of using Google Earth Engine (GEE) for me is the
ability to share analysis results through web map applications. Clients
are usually more engaged when they can interact with a visual platform
that helps them understand the project better. Remote sensing analysis
is often more complex than regular vector processing, so I imagine the
difficulty on to deliver the results with its key preprocessing step.
What makes it even harder is, we often need to switch between remote
sensing desktop apps and present the results.

By using a web map, we make it easier for clients, even those without a
technical background, to explore and understand the intuition of the
analysis : what layers we have, what imagery we use, what imageries we
combined. The interactive map will provide a clearer view of the
project, allowing clients to see the bigger picture and stay engaged
throughout the process. However, I must admit GEE is only a tool to make
best use of it we need a prior fundamental concept of remote sensing,
such as spectral band, enhancement, fusion, PCA, and other remote
sensing pre-processing steps. Because in every script we write there
should be a thinking process on why we do reduction, why we do
enhancement, basically need our judgement to navigate each steps.

I would also like to highlight the importance of domain knowledge when
using remote sensing sources. As I mentioned before GEE is just a
tool--its ability to provide remarkable insights truly depend on the
person utilizing it. We might use the same satellite imagery, but with
domain knowledge the analysis will yield different results.

For example, \emph{The Economist} uses satellite data to track conflict
in real time (FYI, I come across this in CASA Seminar in 2023 during the
time I prepared my graduate's school application), \emph{Pediatrics} use
remote sensing to understand the association of air pollution with
asthma prevalence. \emph{Archaeologists} can utilize remote sensing
alongside other methods to understand landscape of historical sites.
There are \emph{tons} of use cases, right?!

If you are having curious mind like me, check Dr Ollie Ballinger's
github page \href{https://oballinger.github.io/\#}{here} to see how
powerful remote sensing can be when combined with domain knowledge. Ah
yes, he is also a lecturer in Remote Sensing class.

\hypertarget{references-3}{%
\section{References}\label{references-3}}

\bookmarksetup{startatroot}

\hypertarget{classification-i}{%
\chapter{Classification I}\label{classification-i}}

\hypertarget{summary-5}{%
\section{Summary}\label{summary-5}}

Take a deep breath okaaay? as today's lecture is quite intense ! The
lecture is divided into 2 main points: \textbf{how classification is
used} and \textbf{how to do the classifications}. Classification process
in remote sensing often applied in several topics, such as:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.3548}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.6452}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Topics
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Sensor
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Urban expansion/sprawl & Landsat \\
Land Use Changes on driving air pollution & Sentinel 3 : Sea \& Land
Surface Temperature

Sentinel-5: precursors major air pollution \\
Urban green spaces & Several options such as high, medium resolution
imagery ; Lidar-hyperspectral \\
Monitoring forest and illegal practices & Landsat \\
Forest fires & Landsat \\
\end{longtable}

In practice, classification in remote sensing is combined with machine
learning techniques that include training data and testing data. Today's
class focus on classification and regression trees (CART). As a visual
learner, learning using this diagram make me understand the complex
materials better, hope it helps you too.

\includegraphics{images/clipboard-2998853873.png}

One of the challenge using machine learning is OVERFITTING. In simple
terms, overfitting happens when a model fits the training data too well
but performs poorly on new data. There are many ways to deal with
overfitting, such as : (a) Limit how the tree grows (b) Pruning --
Remove unnecessary branches after the tree is built to simplify (c)
Pruning with Alpha Regularization -- Remove leaves, increase the pruning
parameter (α) and find the lowest tree score. The goal is to keep the
tree small without sacrificing performance. (d) Data Splitting -- Divide
data into training (to build the tree) and testing (to evaluate
performance) sets and find the lowest sum residuals in regression tasks

One more thing, as decision tree is not good with new data we could use
another method called random forest. I like to use the Chatgpt analogy
on this: a Decision Tree is like asking one expert for advice meanwhile
a Random Forest is like asking 100 experts, each with a unique take,
then averaging their answers.

\begin{quote}
How does it apply to imagery?
\end{quote}

The idea is to turn each pixel in an image into a specific category,
you'd use image segmentation, which labels each pixel based on
predefined categories. This applies to both of supervised or
unsupervised learning.

\includegraphics[width=6.73958in,height=\textheight]{images/clipboard-3670863260.png}

\hypertarget{application-4}{%
\section{Application}\label{application-4}}

In my understanding, classification in remote sensing will be easier if
object detected having a stark difference. The more differ the object
the easier the detection would be. Then I was thinking about
\textbf{dense object with high irregular shape}, such as informal
settlement. How does the classification work? It must be posing a unique
challenge. Thus, I want to explore how the classification of informal
settlement in small town of Cape Town, South Africa.

Apparently,machine learning with its ability to detect pattern or by
grouping similar area together is really helpful on this. Chamunorwa,
Shoko, and Magidi (2024) tried to compare 4 machine learning algorithm
to detect sparse informal settlement using Gradient Boost, KNN, Random
Forest, and Support Vector Machine {[}SVM{]} with data extracted from
cloud computing repositories.

KNN is valued because its simplicity in classification tasks (effective
for well-defined clusters). Gradient Boosting is valued for its ability
to improve performance through the sequential combination of weak
models, (capturing complex interactions within the data). Meanwhile,
Random Forest : an ensemble method, is good at managing high-dimensional
data and deal with overfitting. SVM is strong in classifying data with
clear margins by creating optimal decision boundaries. Overall, the
Random Forest and Gradient Boosting models were found to be the most
effective for delineating informal settlements with accuracy of 89.07 \%
for RF and 89.05 for Gradient Boosting. It is amazing to see how this
machine learning can capture the different cluster of informal
settlements.

\includegraphics[width=8.35417in,height=\textheight]{images/clipboard-31491687.png}

Figure 1 RF (left) and KNN (left) predicted outcome

I wondered if this same algorithms \textbf{applied} \textbf{to} urban
area with \textbf{different morphology} what will happen, will it
maintain its accuracy or declining. Because we know that each city
experiences different processes and mechanisms, resulting in unique
urban conditions and morphology. It's even molded with different policy
and government's agenda that might shape them into what they are today.

The answer is yes, it can be ! Although they come from different process
Ibrahim et al. (2019) highlight that informal settlements still have
unique identifier that make them distinguishable from formal
settlements. However, they also mentioned that accuracy tends to improve
when the model is trained in areas close to the prediction site.

\hypertarget{reflection-3}{%
\section{Reflection}\label{reflection-3}}

I know that machine learning is really helpful in automation in
classification, however I must admit that it will take time for me to
fully understand what and why of its underlying process. The complexity
of its process and even the interpretation can be overwhelming without
foundation in the principles behind them. Nonetheless, with continuous
learning, exposure, and practice my understanding will gradually
develop, hopefully!

Future applications : I would love to apply classification techniques to
quantify the actual proportion of greenery in urban areas, both planned
greenery or unplanned one. This proportion will then be compared to the
designated urban greenery targets. I am particularly interested in this
because, in my country, local governments are required to allocate at
least 30\% of their total area to green spaces. This analysis will help
answer important questions such as: Have the governments achieved this
target? If so, to what extent? This approach demonstrates how
data-driven decision-making can lead to more informed judgments.

\hypertarget{references-4}{%
\section{References}\label{references-4}}

\bookmarksetup{startatroot}

\hypertarget{classification-ii}{%
\chapter{Classification II}\label{classification-ii}}

Before summarizing everything, I need to bring this to my self when
reflecting back to all the materials for this past 2 weeks.

\includegraphics[width=5.5in,height=\textheight]{images/clipboard-2560646539.png}

Source :
\href{http://medium.com/nybles/understanding-machine-learning-through-memes-4580b67527bf}{Medium}

\hypertarget{summary-6}{%
\section{Summary}\label{summary-6}}

This week continues last week's topic on classification in remote
sensing and explores method to assess the accuracy of our classification
results. Here they are\ldots..and again with easy-to-digest diagram.

\includegraphics{images/clipboard-2572872984.png}

Note : Confusion Matrix's source :
\url{https://google-earth-engine.com/}

\hypertarget{applications}{%
\section{Applications}\label{applications}}

This week I will explore the application of classification technique I
am quite interested in : Object Based Imagery Analysis (OBIA). I am
interested in OBIA because there is a segmentation part in generating
the result. The reason I am interested in OBIA because to me this method
is more human-like classification. It processes image based on
meaningful objects rather than individual pixels. Cool isn't it? So how
does it fit into informal settlements detection?

OBIA need information about relevant bands (such as RGB, NIR, SWIR) and
indices (such as NDVI, NDBI, NDWI) to process the algorithm. In GEE, an
algorithm called simple non-iterative clustering (SNIC) was used to
segment image into super pixels (called it a group of similar pixels)
based on color and spatial coordinates. Then, calculated contextual
characteristics (height, shape, size, texture) afterwards. The combined
spectral and contextual information was used to classify the land cover
using machine learning algorithm such as Random Forest. Gxokwe and Dube
(2024) applied this combined with ground truth and Sentinel 2 to map
informal settlement in Capetown Metropolitan Area, and the result is
shown below, with distribution quite scattered at different places.

\includegraphics{images/clipboard-3948245033.png}

Fig 2. Distribution of informal settlement using Random Forest

In their publication, they mentioned that there are also
misclassification between formal and informal settlements due to similar
spectral values as well as it occupies small area between formal
settlements. This spectral confusion make the producer and user accuracy
lower. I also ponder the same way seeing the result in Figure 2, because
even with my own interpretation the predicted informal and formal
doesn't have distinct feature, except the building's density. Thus, they
suggest using SAR (Synthetic Aperture Radar) to \textbf{improve
deliniation} of informal settlements. Basically, SAR is effective in
this setting because it is sensitive to physical characteristics
(orientation, shape, and distribution) due to its ability to capture
backscatter Gibson, Engelbrecht, and Rush (2019). (Gibson, Engelbrecht,
and Rush 2019) use SAR to complement their analysis on detecting before
and after fire in informal settlements. I will write this-SAR thing on
next week.

After brainstorming with Chatgpt, I become more aware of many type of
challenges linked to informal settlements and how remote sensing can at
least capture this challenges. One of challenges is the dynamic nature
of informal settlement where buildings being constructed, demolished, or
altered frequently. With Sentinel 1 and 2 revisit time \textless{} 5-6
days, it is beneficial to include temporal mapping in monitoring
informal settlements.

\hypertarget{reflection-4}{%
\section{Reflection}\label{reflection-4}}

Remote sensing is interesting but also complex at the same time for me.
It often widens the gap between my willingness to learn and my
understanding of the subject. I'm not sure how to build the confidence
to execute these methodologies when the interpretation and analysis
process is left entirely in my hands. During practical sessions, I can
ask the lecturer, but when I'm out in the real world, people might ask
me questions. ``Am I ready?'' or ``Do I have a solid foundation to
justify what I'm doing with remote sensing and machine learning?'' Even
though I have a love-hate relationship with regression, I'm sure machine
learning will join that club too. However, thinking about the potential
insights I can gain from this does soothe the hard feelings toward these
advanced methodologies

Future application : I genuinely believe that mapping informal
settlements using open-source data from Sentinel-1 and Sentinel-2
presents an opportunity for valuable analysis. For example, questions
like: How does their spatial distribution look? Do they grow rapidly
over time? What are the building materials? We can link this analysis to
risk mitigation for fire brigades. Because in Global South country,
privatization of public lands is common occurrence Bon (2021), and
public land is potential areas for growing informal settlement . As it
is unplanned, there might be no adequate access into this informal
settlements. Additionally, the semi-permanent materials will expose them
vulnerable to fire incidents. Thus, it is interesting to link the
finding in informal settlement mapping with its mitigation risk. We know
that Government also needs to be responsible when this happened, even
when the informal settlements become challenge for their urban planning
projects.

\hypertarget{references-5}{%
\section{References}\label{references-5}}

\bookmarksetup{startatroot}

\hypertarget{synthetic-aperture-radar}{%
\chapter{Synthetic Aperture Radar}\label{synthetic-aperture-radar}}

\hypertarget{summary-7}{%
\section{Summary}\label{summary-7}}

Today's lecture explores sensor imagery called Synthetic Aperture Radar
(SAR). Well the name sounds complicated :) The only word that unfamiliar
for me is `aperture', after asking Chatgpt with prompt of `concise and
explain to 15 years old', I learned that aperture is like the opening of
camera, the wider the aperture the less focus the image captured and the
more light it lets in. Meanwhile, radar is an active sensor that emits
energy for illumination. Due to its longer wavelength, it can penetrate
clouds or dust and capture images at night.

If optical images are like our eyes, \textbf{SAR is like a bat},
emitting chirps of sounds to locate his prey and other objects. It
identifies objects by listening to the reflected signal. The signal that
reflects back to the satellite is called backscatter. There will be a
low backscatter if the signal hits a flat surface and goes off into
space. Meanwhile, it will produce high backscatter when it hits an
object and reflects back to the satellite. SAR images are typically
grayscale; the more signal returned to the satellite, the brighter
(higher value) it appears. I remember that multispectral images have
spectral bands, and this also applies to SAR. There are many bands, but
the most commonly used is the C band, like the bands in Sentinel-1.

\includegraphics[width=7.97917in,height=\textheight]{images/clipboard-3295278254.png}

Figure 1. SAR Bands with frequency and wavelength. Source :
\href{https://www.earthdata.nasa.gov/learn/earth-observation-data-basics/sar}{NASA}

Radar can collect signals with different polarization. Polarization
describes the direction in which the plane of a transmitted
electromagnetic waves move back and forth. When signal emitted in
vertical (V) and received horizontal it indicated V-H, meanwhile when
the signal both emitted and received horizontal it indicated H-H.
Different surface will respond differently to the polarizations, such
as:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.1429}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.8571}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Type of Scattering
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Occurs when\ldots.
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Rough surface scattering & signal interact with irregularities of
surface and most sensitive to VV scattering (example : bare soil or
water) \\
Volume scattering & signal interacts with multiple scatterer such as
leaves in forest, most sensitive to VH or HV \\
Double bounce scattering & signal reflects off two surfaces before
returning back to sensor. This creates strong backscatter and most
sensitive to HH. (example : tree and building). \\
\end{longtable}

Here's the illustration to understand the type of scattering in radar.

\includegraphics[width=4.40625in,height=\textheight]{images/clipboard-4253915995.png}

Figure 2 : Type of scattering. Source :
\href{https://www.earthdata.nasa.gov/learn/earth-observation-data-basics/sar}{NASA}

SAR can be useful in our analysis by comparing change between two
images. By comparing change between two images, we measure the variance
of the appearance over time using 1) standard deviation 2) t-tests 3)
combine with optical data (using technique such as PCA, object based
image analysis, or intensity fusion). Let's use our dearest Google to
get better understanding over this.

\hypertarget{application-5}{%
\section{Application}\label{application-5}}

I would like to mention the application of \textbf{optical remote
sensing versus SAR Imagery} in damage detection during conflict.
Emmm\ldots. this topic is slightly unfamiliar to me but but it has
become one of my growing interests in recent years. \emph{On that day,
as I am curious about this topic I decided to sit in on the practical
session of Building Applications with Big Data.}

During conflict, the need to assess building damage is crucial for
humanitarian relief efforts. However, in the past the detection depended
on \textbf{eyewitness reports and manual detection}. We know that time
is precious during conflict and humanitarian aids. This calls Mueller et
al. (2021) to generate damage monitoring using Very High Resolution
(VHR) satellite imagery, good for its resolution and frequency, and
using machine learning techniques for automation.

The intuition behind the method is using Convolutional Neural Networks
(CNNs) to learns from example of destruction (e.g rubble and bomb
raters) to make predictions about other images. Then to address the
challenges of limited amount of labeled data (because sometimes the
destruction is sparse or only limited buildings destroyed), they use
label-augmentation technique which assumed destroyed at a certain time
building will remain destroyed in subsequent time. This assumption helps
to create additional labels for training dataset. They set a certain
threshold to change the continuous prediction into binary
classificationsl, The result is shown below, showing damage before and
after a heavy weaponry attack in a neighborhood of Aleppo, red : highly
predicted as destroyed, while green : low predicted as destroyed.

\includegraphics{images/clipboard-4242002752.png}

Figure 3 : Damage destruction using optical satellite data. Source :
Mueller et al. (2021).

However, I pondered upon the use of VHR imagery in the analysis as it
must be \textbf{financially expensive,} thus not everyone can get the
access into it. It must be nice to have the open access data for this
damage detection, right? and Ollie, our Remote Sensing lecturer, has
\textbf{found the solution !} He managed to find a new method for
building damage detection using Pixel-Wise T-test (PWTT) and SAR in
Sentinel 1. Yes, you read that right-- it's sentinel 1---which means it
is open access ! Using this algorithm, he could achieve building-level
accuracy higher than deep learning + VHR method (Ballinger 2024). He
uses SAR imagery because it emits a pulse towards the earth and then
measure its return signal, enabling the analysis of how different
textural surface respond differently.

\begin{quote}
\emph{Hang in there with me, this next paragraph gets a little bit
technical. I know it might be a lot, but my curiosity just won't let
this go.}
\end{quote}

The intuition behind the methodology is that he investigates how much of
the radar signal is reflected back to the satellite, which called
backscatter amplitude. Basically, building and rubble will reflected the
radar signal differently. The algorithm then compares the backscatter
amplitude of each pixel during period before the conflict and after the
conflict. To determine, the change in backscatter is significant enough
to be classified as damage, he uses T-test to know how much the
variation over time and take the largest T-value detected as a potential
damage in that pixel. T-test allows us to compare the means joined by
its standard deviation and the sample number. See the figure 2 below,
the green shows condition before invasion while the red is after
invasion. Meanwhile, the dashed line showed the average backscatter
amplitude with ±1 standard deviation before and after the building's
destruction.

\includegraphics[width=5.60417in,height=\textheight]{images/clipboard-2990756776.png}

Figure 4 : Backscatter comparation before and after destruction . Source
: Ballinger (2024)

For me, the performance of open-source data in outperforming VHR
satellite data is a significant finding. Although it should be validated
in different climatic regions, as Ollie mentioned in the paper, it
presents promising potential to be explored. The utilization of
open-source data will encourage faster knowledge development, as people
from diverse backgrounds can explore and find the `rabbit hole.' In
budget-based institutions, if the goal can be easily achieved with
open-source data, it will make spending more effective. However, we must
admit that commercial data might have more strengths, but let's save our
energy here.

\hypertarget{reflection-5}{%
\section{Reflection}\label{reflection-5}}

If SAR is this good at penetrating objects and imaging at night, what
kind of weaknesses does it have? I was thinking when backscattering
signals bounce off back by so many things (many speckles- term for noise
in radar), it must be challenging to analyze. Moreover, the appearance
of SAR images as grayscale is also less intuitive. Apparently, this
question has been explored by Wang and Patel (n.d.), they address the
grayscale and speckle issues by applying convolutional neural nets
(CNNs). I am not sure if I can fully understand what it means, but the
intuition is to make SAR images appear more like the visible images by
despeckled and colorized image.

In the future, I would really like to use SAR to assess landslide
risk\textbf{.} In my hometown, hill areas are famous with its scenic
view and forest-like nuance however it is really prone to land slide.
Even when I drive pas through the road, there are lots of sign ``Beware
of potential Land Slide''. With a high density of vegetation in such
settings, using SAR in Sentinel 1 will be perfect to assess this
condition. However, I must admit the journey to really use SAR and
interpret the data will be very challenging for me.

\hypertarget{references-6}{%
\section*{References}\label{references-6}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-arshad2023}{}}%
Arshad, Arslan, Junaid Zulfiqar, Muhammad Hassan Zaib, Ahsan Khan, and
Muhammad Jahanzeb Khan. 2023. {``Mapping Socioeconomic Conditions Using
Satellite Imagery: A Computer Vision Approach for Developing
Countries.''} \emph{Journal of Economy and Technology} 1 (November):
144--63. \url{https://doi.org/10.1016/j.ject.2023.11.001}.

\leavevmode\vadjust pre{\hypertarget{ref-ballinger2024}{}}%
Ballinger, Ollie. 2024. {``Open Access Battle Damage Detection via
Pixel-Wise t-Test on Sentinel-1 Imagery,''} May.
\url{https://doi.org/10.48550/ARXIV.2405.06323}.

\leavevmode\vadjust pre{\hypertarget{ref-bappenas2021}{}}%
Bappenas, Kementrian PPN. 2021. {``Buku Saku Pemindahan Ibu Kota
Negara.''}

\leavevmode\vadjust pre{\hypertarget{ref-benabbes2024}{}}%
Ben Abbes, Ali, Jeaneth Machicao, Pedro L. P. Corrêa, Alison Specht,
Rodolphe Devillers, Jean P. Ometto, Yasuhisa Kondo, and David Mouillot.
2024. {``DeepWealth: A Generalizable Open-Source Deep Learning Framework
Using Satellite Images for Well-Being Estimation.''} \emph{SoftwareX} 27
(September): 101785. \url{https://doi.org/10.1016/j.softx.2024.101785}.

\leavevmode\vadjust pre{\hypertarget{ref-bon2021}{}}%
Bon, Bérénice. 2021. {``Making Railway Land Productive: The
Commodification of Public Land in Kenyan and Indian Cities.''}
\emph{Geoforum} 122 (June): 118--28.
\url{https://doi.org/10.1016/j.geoforum.2020.12.015}.

\leavevmode\vadjust pre{\hypertarget{ref-capitalauthority2024}{}}%
Capital Authority, Nusantara. 2024. {``Nusantara Sustainable Development
GOals (SDGs) Voluntary Local Review Baseline.''}

\leavevmode\vadjust pre{\hypertarget{ref-chamunorwa2024}{}}%
Chamunorwa, Brighton, Moreblessings Shoko, and James Magidi. 2024.
{``Low-Cost and Scalable Detection of Sparse Informal Settlements Using
Machine Learning in Gcuwa, Eastern Cape, South Africa.''} \emph{African
Geographical Review}, July, 1--17.
\url{https://doi.org/10.1080/19376812.2024.2375376}.

\leavevmode\vadjust pre{\hypertarget{ref-gibson2019}{}}%
Gibson, Lesley, Jeanine Engelbrecht, and David Rush. 2019. {``Detecting
Historic Informal Settlement Fires with Sentinel 1 and 2 Satellite Data
- Two Case Studies in Cape Town.''} \emph{Fire Safety Journal} 108
(September): 102828.
\url{https://doi.org/10.1016/j.firesaf.2019.102828}.

\leavevmode\vadjust pre{\hypertarget{ref-gxokwe2024}{}}%
Gxokwe, Siyamthanda, and Timothy Dube. 2024. {``Using Cloud Computing
Techniques to Map the Geographic Extent of Informal Settlements in the
Greater Cape Town Metropolitan Area.''} \emph{Remote Sensing
Applications: Society and Environment} 36 (November): 101275.
\url{https://doi.org/10.1016/j.rsase.2024.101275}.

\leavevmode\vadjust pre{\hypertarget{ref-han2025}{}}%
Han, Yuan, Jianhua He, Xiaoping Du, Xiao Han, and Yaolin Liu. 2025.
{``Reconstructing Urban Vegetation Evolution in China Using Multimodal
Deep Learning and 30-Years Landsat Archive.''} \emph{Urban Forestry \&
Urban Greening} 103 (January): 128582.
\url{https://doi.org/10.1016/j.ufug.2024.128582}.

\leavevmode\vadjust pre{\hypertarget{ref-ibrahim2019}{}}%
Ibrahim, Mohamed R., Helena Titheridge, Tao Cheng, and James Haworth.
2019. {``predictSLUMS: A New Model for Identifying and Predicting
Informal Settlements and Slums in Cities from Street Intersections Using
Machine Learning.''} \emph{Computers, Environment and Urban Systems} 76
(July): 31--56.
\url{https://doi.org/10.1016/j.compenvurbsys.2019.03.005}.

\leavevmode\vadjust pre{\hypertarget{ref-li2023a}{}}%
Li, Saibo, Shaoyang He, Tianxiang Yue, Zhengping Du, Na Zhao, Yapeng
Zhao, Yimeng Jiao, et al. 2023. {``Mapping Bamboo Forest and Expansion
Intensity in China by Coupling Vegetation Phenology and C-Band SAR with
Sentinel-1 and Sentinel-2 Images.''} \emph{International Journal of
Applied Earth Observation and Geoinformation} 121 (July): 103384.
\url{https://doi.org/10.1016/j.jag.2023.103384}.

\leavevmode\vadjust pre{\hypertarget{ref-ministryofhealth2023}{}}%
Ministry of Health, Directorate General of Disease Prevention, and
Control. 2023. {``National Action Plan for Acceleration of Malaria
Elimination 2020-2026 (Revision).''}
\url{https://malaria.kemkes.go.id/sites/default/files/2024-08/National\%20Strategic\%20Plan\%20Revision_Malaria_29\%20Mei\%202023.pdf}.

\leavevmode\vadjust pre{\hypertarget{ref-mueller2021}{}}%
Mueller, Hannes, Andre Groeger, Jonathan Hersh, Andrea Matranga, and
Joan Serrat. 2021. {``Monitoring War Destruction from Space Using
Machine Learning.''} \emph{Proceedings of the National Academy of
Sciences of the United States of America} 118 (23): e2025400118.
\url{https://doi.org/10.1073/pnas.2025400118}.

\leavevmode\vadjust pre{\hypertarget{ref-naserrudin2023a}{}}%
Naserrudin, Nurul Athirah, Pauline Yong Pau Lin, April Monroe, Richard
Culleton, Sara Elizabeth Baumann, Shigeharu Sato, Bipin Adhikari, et al.
2023. {``Exploring Barriers to and Facilitators of Malaria Prevention
Practices: A Photovoice Study with Rural Communities at Risk to
Plasmodium Knowlesi Malaria in Sabah, Malaysia.''} \emph{BMC Public
Health} 23 (1): 1316. \url{https://doi.org/10.1186/s12889-023-16173-x}.

\leavevmode\vadjust pre{\hypertarget{ref-naserrudin2023}{}}%
Naserrudin, Nurul Athirah, Pauline Pau Lin Yong, April Monroe, Richard
Culleton, Sara Elizabeth Baumann, Shigeharu Sato, Rozita Hod, Mohammad
Saffree Jeffree, Kamruddin Ahmed, and Mohd Rohaizat Hassan. 2023.
{``Seeing Malaria Through the Eyes of Affected Communities: Using
Photovoice to Document Local Knowledge on Zoonotic Malaria Causation and
Prevention Practices Among Rural Communities Exposed to Plasmodium
Knowlesi Malaria in Northern Borneo Island.''} \emph{Malaria Journal} 22
(1): 166. \url{https://doi.org/10.1186/s12936-023-04603-5}.

\leavevmode\vadjust pre{\hypertarget{ref-nationalacademyofsciences.2003}{}}%
National Academy of Sciences. 2003. \emph{Using Remote Sensing in State
and Local Government: Information for Management and Decision Making}.
Washington D.C: The National Academies Press.

\leavevmode\vadjust pre{\hypertarget{ref-surendra2024}{}}%
Surendra, Henry, Bimandra A. Djaafara, Helen D. Prameswari, Dedy
Supriyanto, Ponco Waluyo, Setyo B. Basuki, Herdiana Herdiana, et al.
2024. {``Mitigating Risks of Malaria and Other Vector-Borne Diseases in
the New Capital City of Indonesia.''} \emph{Nature Communications} 15
(1): 10575. \url{https://doi.org/10.1038/s41467-024-54891-x}.

\leavevmode\vadjust pre{\hypertarget{ref-urbanre}{}}%
{``Urban Renewal Mapping: A Case Study in Beijing from 2000 to 2020.''}
n.d. \url{https://spj.science.org/doi/10.34133/remotesensing.0072}.

\leavevmode\vadjust pre{\hypertarget{ref-wang}{}}%
Wang, Puyang, and Vishal M. Patel. n.d. {``Generating High Quality
Visible Images from SAR Images Using CNNs.''}
\url{https://doi.org/10.48550/ARXIV.1802.10036}.

\leavevmode\vadjust pre{\hypertarget{ref-who2021}{}}%
WHO, World Health Organization. 2021. {``Global Technical Strategy for
Malaria 2016{\textendash}2030, 2021 Update.''}

\leavevmode\vadjust pre{\hypertarget{ref-wimberly2021}{}}%
Wimberly, Michael C., Kirsten M. de Beurs, Tatiana V. Loboda, and
William K. Pan. 2021. {``Satellite Observations and Malaria: New
Opportunities for Research and Applications.''} \emph{Trends in
Parasitology} 37 (6): 525--37.
\url{https://doi.org/10.1016/j.pt.2021.03.003}.

\leavevmode\vadjust pre{\hypertarget{ref-yilmaz2024}{}}%
Yılmaz, Okan, and Mehmet Alkan. 2024. {``Assessing the Impact of
Unplanned Settlements on Urban Renewal Projects with GEE.''}
\emph{Habitat International} 149 (July): 103095.
\url{https://doi.org/10.1016/j.habitatint.2024.103095}.

\end{CSLReferences}



\end{document}
